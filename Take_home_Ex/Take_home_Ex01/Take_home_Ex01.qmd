---
title: "Dynamic Patterns of Public Transport Usage"
author: "Wan Kee"
date: "25 November 2023"
date modified: "25 November 2023"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# **A Geospatial Analysis of Bus Stop Passenger Volume in Urban Environments**

# 1.1 Overview

In the intricate mosaic of urban transportation, bus stops serve as pivotal nodes that capture the pulse of city life through the ebb and flow of passenger trips. The study of passenger trip traffic, particularly during peak hours, becomes essential for enhancing service efficiency, planning urban infrastructure, and improving the overall commuter experience. This geospatial analysis is anchored in the bustling landscape of a metropolitan area, where data on bus stops, resident population distribution, urban development plans (master plan sub-zones), and passenger volume intertwine to paint a comprehensive picture of transit dynamics.

This analysis aims to dissect the rhythms of urban mobility with the following objectives:

1.  **Geovisualization and Analysis**

    -   Compute the passenger trips generated by origin at the hexagon level
    -   Visualize the geographical distribution of the passenger trips

2.  **Local Indicators of Spatial Association (LISA) Analysis**

    -   Compute LISA of the passengers trips generate by origin at hexagon level
    -   Visualize the LISA maps of the passengers trips generate by origin at hexagon level

3.  **Emerging Hot Spot Analysis (EHSA)**

    -   Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values
    -   Visualize EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level

# 1.2 Load packages

`sf` imports geospatial data and `readr` imports csv file.

`tidyverse` performs data import, wrangling and visualization. `dplyr` perform relational join.

`spdep` compute spatial weights and calculate spatially lagged variables.

```{r}
pacman::p_load(sf, readr, dplyr, ggplot2, knitr, mapview, spdep, tmap, tidyverse)
```

# 1.3 Import data

We will be using the following geospatial (`busstops`,  `mpsz`) and aspatial (`odbus`, `pop`) datasets:

::: panel-tabset
## Bus Stops
`busstops` contains the detailed information for all bus stops currently serviced by buses, including bus stop code, road name, description, location coordinates.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/BusStops))

```{r}
busstops <- st_read(dsn = "data/BusStopLocation_Jul2023", layer = "BusStop") %>%
  st_transform(crs = 3414)
```
The output indicates that the geospatial objects are **point** features. There are **5161 features** and 3 fields. It is in **SVY21** projected coordinates system with **XY** dimension.

## Passenger Volume
`odbus` contains the number of trips by weekdays and weekends from origin to destination bus stops. It reflects the passenger trip traffic for **October 2023**.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/PV/ODBus))

```{r}
odbus = read_csv("data/origin_destination_bus_202310.csv")
```
The output does not indicate any geospatial objects. There are **5,694,297 records** and 7 fields.

## Population
`pop` contains Singapore residents grouped by planning Area or subzone, age group, sex and floor area of residence. The data period is from **June 2011 onwards**. From June 2011 to 2019, the planning areas refer to areas demarcated in the Master Plan 2014, and from June 2020 onwards will be Master Plan 2019.

| x    | Description          |
|------|----------------------|
| PA   | Planning area        |
| SZ   | Subzone              |
| AG   | Age group            |
| Sex  | Sex                  |
| FA   | Residence floor area |
| Pop  | Resident count       |
| Time | Time/period          |

Source: Department of Statistics ([Link](https://www.singstat.gov.sg/-/media/files/find_data/population/statistical_tables/respopagesexfa2011to2020.ashx))

```{r}
pop <- read_csv("data/respopagesexfa2011to2020/respopagesexfa2011to2020.csv")
```

## Subzone
`mpsz` is the Master Plan 2019, a forward looking guiding plan for Singapore's development in the medium term over the next 10 to 15 years published in **2019**. Note this `mpsz` differs from that in previous chapter, [Data Wrangling](https://cosmic-kitten.netlify.app/hands_on_ex/hands_on_ex01/hands_on_ex01).

Source: URA (Download [here](https://beta.data.gov.sg/collections/1749/view))

```{r}
mpsz = st_read(dsn="data/MPSZ-2019", layer="MPSZ-2019") %>% 
  st_transform(crs=3414)
```
The output indicates that the geospatial objects are **multipolygon** features. There are **332 features** and 6 fields. It is in **WGS84** projected coordinates system with **XY** dimension.

```{r}
# Assuming mpsz is your sf object
#mpsz <- st_read(dsn="data/MP19_SUBZONE", layer="MP19_SUBZONE_NO_SEA")

# Ensure that 'geometry' is the active geometry column
#mpsz <- st_set_geometry(mpsz, "geometry")

# Check for invalid geometries and apply st_make_valid if needed
#mpsz$geometry_is_valid <- st_is_valid(mpsz$geometry)
#mpsz <- mpsz %>%
#  mutate(geometry = ifelse(!geometry_is_valid, st_make_valid(geometry), geometry))

# Now, remove the Z dimension explicitly if it exists
#mpsz <- st_zm(mpsz, drop = TRUE, what = "Z")

# View the data structure to confirm changes
#print(mpsz1)
```

::: {.callout-tip title="Warning"}
Warning: GDAL Message 1: Sub-geometry 0 has coordinate dimension 2, but container has 3
:::

The warning message indicate that a discrepancy in the dimensionality of the geometries in `mpsz` Shapefile. Some of the sub-geometries have 2D coordinates (X and Y), while the overall container expects 3D coordinates (X, Y, and Z). The `st_zm(what = "Z")` function drops the Z dimension from the geometries, which eliminate the warnings about coordinate dimensions. We are not performing 3D analysis, this approach should work fine for most applications.
:::

# 1.4 Create Spatial Grids

Spatial grids are commonly used in spatial analysis to divide the study area into equal size, regular polygons that tessellate the area of interest. On the selection of grid, regular geographic units, such as square grid or fishnets, rarely reflect real world situations. Hexagons are compact shape and can overcome oddly-shaped geographical units.

**Step 1: Create a hexgonal grid**

`hexagon` is a hexagon layer of 250m where the distance is the perpendicular distance between the centre of the hexagon and its edges. It is a substitute for 'mpsz' which is relatively coarse and irregular.

::: Panel-tabset
## Step 1
```{r}
# Create hexagonal grid (250m from center to edges) and add grid ID.
area_hexagon_grid = st_make_grid(busstops, cellsize = 500, what = "polygons", square = FALSE)

hexagon_grid_sf = st_sf(area_hexagon_grid) %>% 
  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))
hexagon_grid_sf
```
The output indicates that the geospatial objects are **polygon** features. There are **5580 features** and 1 fields. It is in **SVY21** projected coordinates system with **XY** dimension.

## Step 2
```{r}
# Count the number of bus stops in each grid and remove grids without any value.
hexagon_grid_sf$grid_id = lengths(st_intersects(hexagon_grid_sf, busstops))
hexagon_count = filter(hexagon_grid_sf, grid_id > 0)
hexagon_count
```
The output indicates that the geospatial objects retained **polygon** features and there are more than one polygon feature in a grid_id. The intersection of `busstops` and `hexagon_grid_sf` is **1524 features** and 1 fields, indicating only 1524 out of 5580 features contains bus stops. It is in **SVY21** projected coordinates system with **XY** dimension.

## Step 3
```{r}
# Set tmap to view mode for interactive plotting.
tmap_mode("view")
hexagon = tm_shape(hexagon_count)+
  tm_fill(
    col = "grid_id",
    palette = "Reds",
    style = "cont",
    title = "Number of Bus Stops in Singapore",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  )+
  tm_borders(col = "grey40", lwd = 0.7)
hexagon
```
The geospatial distribution of bus stops in Singapore, as visualized in the above map, is extensive and dispersed throughout the central region, with a notable concentration of stops with darker shades of red signifying higher concentrations. Outlying regions, along the coastal areas, show fewer bus stops as indicated by the presence of lighter-colored hexagons or even white spaces where no stops are present. This distribution pattern suggests a robust public transportation infrastructure in urban and densely populated areas, tapering off in less populated or industrial regions.
:::

# 1.5 Explore data

`st_geometry()` displays basic information of the feature class, such as type of geometry, the geographic extent of the features and the coordinate system of the data. `glimpse()` transposes the columns in a dataset and makes it possible to see the column name, data type and values in every column in a data frame.

::: panel-tabset
## Bus Stops
```{r}
st_geometry(busstops)
```
```{r}
glimpse(busstops)
```
## Passenger Volume
```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)
glimpse(odbus)
```
## Population
```{r}
glimpse(pop)
```
```{r}
popdata2020 <- pop %>%
  filter(Time == 2020) %>%
  group_by(PA, SZ, AG) %>%
  summarise(`POP` = sum(`Pop`)) %>%
  ungroup()%>%
  pivot_wider(names_from=AG, 
              values_from=POP) %>%
  mutate(YOUNG = rowSums(.[3:6])
         +rowSums(.[12])) %>%
mutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+
rowSums(.[13:15]))%>%
mutate(`AGED`=rowSums(.[16:21])) %>%
mutate(`TOTAL`=rowSums(.[3:21])) %>%  
mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)
/`ECONOMY ACTIVE`) %>%
  select(`PA`, `SZ`, `YOUNG`, 
       `ECONOMY ACTIVE`, `AGED`, 
       `TOTAL`, `DEPENDENCY`)
```
## Subzone

```{r}
glimpse(mpsz)
```

## Population in Subzones

convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.


```{r}
mpsz_pop<- left_join(mpsz, pop_category,
                     by = c("SUBZONE_N" = "SZ"))
```

:::

# 1.5 Plot data

`mapview` creates interactive visualisations of spatial data to examine and visually investigate both aspects of spatial data, the geometries and their attributes.

`plot()` takes parameters for specifying points in the diagram. At its simplest, it can plot two numbers against each other. With datasets, it can generate maps and plot the specified columns/attributes, with default up to nine plots or maximum all plots.

::: panel-tabset
## Bus Stops

```{r}
mapview(busstops, cex = 3, alpha = 0.5, popup = NULL)
```

## Bus Stops (high density)

## 1.6.1 Compute the bus stop density

```{r}
# Filter hexagons that contain more than 8 bus stops
hexagon_red = filter(hexagon_grid_sf, grid_id>8)

tmap_mode("view")
redhex = tm_shape(hexagon_red)+
  tm_fill(
    col = "grid_id",
    palette = "Reds",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  )+
  tm_borders(col = "grey40", lwd = 0.7)
redhex
```

Sembawang MRT (9 bus stops)
![](images/Screenshot%202023-11-26%20at%206.01.46%E2%80%AFPM.png){fig-align="left" width="700"}

Pasir Ris (11 bus stops)
![](images/Screenshot%202023-11-27%20at%202.20.59%E2%80%AFAM.png){fig-align="left" width="700"}

## Passenger Volume
```{r}
# Summarize the total trips by day type
total_trips <- odbus %>%
  group_by(DAY_TYPE) %>%
  summarise(total = sum(TOTAL_TRIPS))

# Plot using ggplot2
ggplot(total_trips, aes(x = DAY_TYPE, y = total, fill = DAY_TYPE)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Total Trips by Day Type", x = "Day Type", y = "Total Trips")
```
## Population


## Subzone
```{r}
plot(mpsz["PLN_AREA_N"])
```
## Population in Subzone

:::

# 1.6 Geovisualisation and Analysis

## 1.6.2 Compute the passenger trips generated by origin

### Step 1: Classify by time interval
```{r}
# Function to assign peak and non-peak times
time_interval <- function(day_type, time_per_hour) {
  if (day_type == "WEEKDAY") {
    if (time_per_hour >= 6 & time_per_hour <= 9) {
      "morning peak"
    } else if (time_per_hour >= 17 & time_per_hour <= 20) {
      "afternoon peak"
    } else {
      "non peak"
    }
  } else if (day_type == "WEEKENDS/HOLIDAY") {
    if (time_per_hour >= 11 & time_per_hour <= 14) {
      "morning peak"
    } else if (time_per_hour >= 16 & time_per_hour <= 19) {
      "evening peak"
    } else {
      "non peak"
    }
  } else {
    "non peak"
  }
}

# Assuming 'odbus' is your data frame
odbus$TIME <- mapply(time_interval, odbus$DAY_TYPE, odbus$TIME_PER_HOUR)

# Checking the first few rows of the data frame to verify the new column
head(odbus)
```

### Step 2: Join datasets

```{r}
passengertrips <- left_join(busstops, odbus, 
                            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

::: panel-tabset
#### Day

```{r}
passengertrips_day <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY"], na.rm = TRUE),
    .groups = "drop"
  )
```

#### Time

Determine peak or non peak

```{r}
passengertrips_time <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKDAY_AFTERNOON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "afternoon peak"], na.rm = TRUE),
    WEEKDAY_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "evening peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    .groups = "drop"
  )

passengertrips_time <- passengertrips_time %>% 
  filter(!(WEEKDAY_MORNING_PEAK == 0 
           & WEEKDAY_AFTERNOON_PEAK == 0
           & WEEKDAY_NON_PEAK == 0
           & WEEKENDS_HOLIDAYS_MORNING_PEAK == 0
           & WEEKENDS_HOLIDAYS_EVENING_PEAK == 0
           & WEEKENDS_HOLIDAYS_NON_PEAK == 0))
```
:::

### Step 3: Ensure both datasets are in the same coordinate reference system (CRS).

::: panel-tabset
#### Day

```{r}
st_crs(passengertrips_day)
```

#### Time

```{r}
st_crs(passengertrips_time)
```

#### Hexagon grid

```{r}
st_crs(hexagon_grid_sf)
```
:::

### Step 4: Perform a spatial join to match trips to hexagons

::: panel-tabset
#### Day

```{r}
passengergrid_day <- st_join(hexagon_grid_sf, passengertrips_day, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_day <- passengergrid_day %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_day)
```

#### Time

```{r}
passengergrid_time <- st_join(hexagon_grid_sf, passengertrips_time, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_time <- passengergrid_time %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_time)
```
:::

### Step 5: Split passengers trip into weekday and weekend

::: panel-tabset 
#### Day
```{r}
# Subset for Weekday
weekday_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekday_trips = sum(WEEKDAY_TRIPS, na.rm = TRUE),
  )

# Subset for Weekend
weekend_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekend_trips = sum(WEEKENDS_HOLIDAYS_TRIPS, na.rm = TRUE),
  )
```

#### Time
```{r}
# First, ensure all necessary columns are present in the dataframe
passengergrid_clean <- passengergrid_time %>%
  mutate(
    WEEKDAY_MORNING_PEAK = ifelse(is.na(WEEKDAY_MORNING_PEAK), 0, WEEKDAY_MORNING_PEAK),
    WEEKDAY_AFTERNOON_PEAK = ifelse(is.na(WEEKDAY_AFTERNOON_PEAK), 0, WEEKDAY_AFTERNOON_PEAK),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_MORNING_PEAK), 0, WEEKENDS_HOLIDAYS_MORNING_PEAK),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_EVENING_PEAK), 0, WEEKENDS_HOLIDAYS_EVENING_PEAK)
  )

# Function to summarise and filter bus stops with no trips
summarise_and_filter <- function(data, column) {
  data %>%
    group_by(BUS_STOP_N) %>%
    summarise(Total_Trips = sum({{ column }}, na.rm = TRUE)) %>%
    filter(Total_Trips > 0) %>%
    ungroup()
}

# Create subsets using the function
weekday_morning_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKDAY_MORNING_PEAK)

weekday_afternoon_peak <- summarise_and_filter(passengergrid_clean, 
                                               WEEKDAY_AFTERNOON_PEAK)

weekend_morning_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKENDS_HOLIDAYS_MORNING_PEAK)

weekend_evening_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKENDS_HOLIDAYS_EVENING_PEAK)

# Check for any BUS_STOP_N that might still have issues
problematic_stops <- passengergrid_clean %>%
  filter(is.na(BUS_STOP_N)) %>%
  pull(BUS_STOP_N) %>%
  unique()

# If problematic_stops has any values, you may need to address these specifically,
# for example by removing them from passengergrid_clean before creating the subsets
if (length(problematic_stops) > 0) {
  passengergrid_clean <- passengergrid_clean %>%
    filter(!(BUS_STOP_N %in% problematic_stops))
}
```

### Step 6: Plot passenger trips traffic

::: panel-tabset
#### Weekday Trips

```{r}
# Convert your data to an sf object if it's not one already
weekday_sf <- st_as_sf(weekday_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_sf$weekday_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_sf) +
  tm_polygons("weekday_trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekday Morning Peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_morning_peak_sf <- st_as_sf(weekday_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "weekday_morning_peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "weekday_morning_peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekday afternoon_peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_afternoon_peak_sf <- st_as_sf(weekday_afternoon_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_afternoon_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_afternoon_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Afternoon Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Afternoon Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekend Trips

```{r}
# Convert your data to an sf object if it's not one already
weekend_sf <- st_as_sf(weekend_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_sf$weekend_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_sf) +
  tm_polygons("weekend_trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekend morning peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_morning_peak_sf <- st_as_sf(weekend_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Morning Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Morning Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekend evening peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_evening_peak_sf <- st_as_sf(weekend_evening_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_evening_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_evening_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Evening Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Evening Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```
:::

# 1.6 Local Indicators of Spatial Association (LISA) Analysis

## 1.6.1 Compute LISA of the passengers trips generate by origin at hexagon level.

### Method 1: Computing Contiguity Spatial Weights

`poly2nb` defines the spatial relationship between different regions by computing contiguity weight matrices and build a neighbours list based on regions with contiguous boundaries.

:::panel-tabset

#### Day
```{r}
passengergrid_day_total <- passengergrid_day %>%
  mutate(TOTAL_TRIPS = WEEKDAY_TRIPS + WEEKENDS_HOLIDAYS_TRIPS)
```

```{r}
wm_q_day <- poly2nb(passengergrid_day_total, queen=TRUE)
summary(wm_q_day)
```
The output shown is a summary of a neighbors list object using Queen contiguity weight matrix. There are **5,029 regions** and approximately **42.69%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **21.47 neighboring regions**. For poorly connected regions, there are 7 regions without neighbors and 14 regions with 1 neighbour. There are 8 well-connected regions with 48 neighbours.

#### Time
```{r}
passengergrid_time_total <- passengergrid_time %>% 
  mutate(TOTAL_TRIPS = WEEKDAY_MORNING_PEAK + WEEKDAY_AFTERNOON_PEAK + WEEKDAY_NON_PEAK +
           WEEKENDS_HOLIDAYS_MORNING_PEAK + WEEKENDS_HOLIDAYS_EVENING_PEAK + WEEKENDS_HOLIDAYS_NON_PEAK)
```

```{r}
wm_q_time <- poly2nb(passengergrid_time_total, queen=TRUE)
summary(wm_q_time)
```
The output shown is a summary of a neighbors list object. There are **5,029 regions** and approximately **42.69%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **21.47 neighboring regions**. For poorly connected regions, there are 7 regions without neighbors and 14 regions with 1 neighbour. There are 8 well-connected regions with 48 neighbours.
:::

### Method 2: Computing distance based neighbours

`passengergrid` is made up of polygons features, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. 
```{r}
longitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[1]])
latitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[2]])
```

```{r}
coords <- cbind(longitude, latitude)
head(coords)
```
```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```
The summary report shows that the largest first nearest neighbour distance is **16228.8km**, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

```{r}
wm_d16229 <- dnearneigh(coords, 0, 16229, longlat = TRUE)
wm_d16229
```
```{r}
# Make a new list with only the first 5 elements
wm_d16229_subset <- wm_d16229[1:5]

# Now use str() on this subset
str(wm_d16229_subset)
```

derive a spatial weight matrix based on Inversed Distance method.

```{r}
dist_day <- nbdists(wm_q_day, coords, longlat = TRUE)
ids_day <- lapply(dist, function(x) 1/(x))
ids_day
```









# 1.6.2 Display the LISA maps of the passengers trips generate by origin at hexagon level.

# 1.7 Emerging Hot Spot Analysis (EHSA)

# 1.7.1 Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values.

# 1.7.2 Prepared EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level.

# weekday evening peak passenger trips by origin; hexagons dont not have shared boundary; isolated with no neighbours but a hotspot.
