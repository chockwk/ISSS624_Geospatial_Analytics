---
title: "Dynamic Patterns of Public Transport Usage"
author: "Wan Kee"
date: "25 November 2023"
date modified: "25 November 2023"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: source
---

# **A Geospatial Analysis of Passenger Volume in Urban Environments**

# 1.1 Overview

In the intricate mosaic of urban transportation, bus stops serve as pivotal nodes that capture the pulse of city life through the ebb and flow of passenger trips. The study of passenger trip volume, particularly during peak hours, becomes essential for enhancing service efficiency, planning urban infrastructure, and improving the overall commuter experience.

This geospatial analysis is anchored in the bustling landscape of a metropolitan area, where data on bus stops, population distribution, urban development plans, and passenger volume intertwine to paint a comprehensive picture of transit dynamics.

This analysis aims to dissect the rhythms of urban mobility in Singapore through **geovisualization** and **emerging hot spot analysis (EHSA)** through spatio-temporal attributes.

# 1.2 Load packages

The analysis involves the following packages:

-   `sf` imports and handles geospatial data
-   `DT` enables R data objects (matrices or data frames) to be displayed as tables on HTML pages.
-   `tidyverse` performs aspatial data import, wrangling and visualization
-   `spdep` compute spatial weights and spatially lagged variables
-   `spfep` compute spatial autocorrelation
-   `mapview` and `tmap` supports data visualisation

```{r}
pacman::p_load(sf, DT, gridExtra, knitr, mapview, spdep, sfdep, tmap, tidyverse)
```

# 1.3 Import data

We will be using the following **geospatial** (`busstop`, `subzone`) and **aspatial** (`odbus`, `malls`) datasets.

`st_geometry()` displays basic information of the feature class, such as type of geometry, the geographic extent of the features and the coordinate system of the data. `glimpse()` transposes the columns in a dataset and makes it possible to see the column name, data type and values within a data frame.

::: panel-tabset
## Bus Stop

`busstop` is a **geospatial** dataset containing the detailed information for all bus stops currently serviced by buses, including bus stop code, road name, description, location coordinates. 

The output indicates that the geospatial objects are **point** features. There are **5161 features** and 3 fields. It is in **SVY21** projected coordinates system with **XY** dimension.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/BusStops))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop <- st_read(dsn = "data/BusStopLocation_Jul2023", layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
st_geometry(busstop)
```

## Subzone

`mpsz` is is a **geospatial** dataset of the Master Plan 2019, a forward looking guiding plan for Singapore's development in the medium term over the next 10 to 15 years published in **2019**. Note this `mpsz` differs from that in previous chapter, [Data Wrangling](https://cosmic-kitten.netlify.app/hands_on_ex/hands_on_ex01/hands_on_ex01).

The output indicates that the geospatial objects are **multipolygon** features. There are **332 features** and 6 fields. It is in **WGS84** projected coordinates system with **XY** dimension.

Source: URA (Download [here](https://beta.data.gov.sg/collections/1749/view))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
mpsz = st_read(dsn="data/MPSZ-2019", layer="MPSZ-2019") %>% 
  st_transform(crs=3414)
```

## Passenger Volume

`odbus` is an **aspatial** dataset containing the number of trips by weekdays and weekends from origin to destination bus stops. It reflects the passenger trip traffic and the most recent dataset from **October 2023** will be used. 

The output indicates **5,694,297 records** and 7 fields. The bus stop codes are converted into factor for data handling.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/PV/ODBus))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus = read_csv("data/origin_destination_bus_202310.csv")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)
glimpse(odbus)
```

## Population

`pop` is an **aspatial** dataset of Singapore residents grouped by planning area or subzone, age group, sex and floor area of residence. The data period is from **June 2011 onwards**. From June 2011 to 2019, the planning areas refer to areas demarcated in the Master Plan 2014, and from June 2020 onwards will be Master Plan 2019.

The output indicates **738,492 records** and 7 fields to illustrate the population distribution by planning area (PA), subzone (SZ), age group (AG), residence floor area (FA), resident count (Pop).

Source: Department of Statistics ([Link](https://www.singstat.gov.sg/-/media/files/find_data/population/statistical_tables/respopagesexfa2011to2020.ashx))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
pop <- read_csv("data/respopagesexfa2011to2020/respopagesexfa2011to2020.csv")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(pop)
```
## Malls

`malls` is an aspatial transformed **spatial** dataset of shopping malls listed on a wikipedia site with SVY21 coordinates retrieved from One Map API. `st_as_sf()` and `st_transforms()` uses the `longitude` and `latitude` to create spatial objects.

The output indicates that the geospatial objects are **point** features. There are **184 features** and 5 fields.

Source: Valary Lim ([GitHub](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/README.md))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
malls <- read_csv("data/mall_coordinates_updated.csv")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
malls_sf <- st_as_sf(malls,
                     coords = c("longitude","latitude"),
                     crs = 4326,
                     remove = F) %>% 
  st_transform(crs = 3414)
glimpse(malls_sf)
```
:::

# 1.4 Create Spatial Grids

**Spatial grids** are commonly used in spatial analysis to divide the study area into equal size, regular polygons that tessellate the area of interest. Square grid rarely reflect real world situations, whereas **hexagons** are compact and can overcome oddly-shaped geographical units.

`hexagon` is a hexagon layer of 250m where the distance is the perpendicular distance between the centre of the hexagon and its edges. It is a substitute for multipolygon in `mpsz` which is relatively coarse and irregular.

::: panel-tabset
## Step 1

First, we will create hexagonal grids using `st_make_grid()` to cover the geometry of `busstop`.

The output indicates that the geospatial objects are **polygon** features. There are **5580 features** and 1 fields. It is in **SVY21** projected coordinates system with **XY** dimension, same as that in `busstop` dataset.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
area_hexagon_grid = st_make_grid(busstop, cellsize = 500, what = "polygons", square = FALSE)
area_hexagon_grid
```

## Step 2

We also assign grid id to each hexagon using `length()` to calculate the length of the geometry and generate a sequence from 1 to the length of vectors in `area_hexagon_grid`.

The output indicates that the geospatial objects retained **polygon** features and there are more than one polygon feature in a grid_id. The intersection of `busstop` and `hexagon_grid_sf` yields **1524 features** and 1 fields, indicating only 1524 out of 5580 features contains bus stops. It is in **SVY21** projected coordinates system with **XY** dimension.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
hexagon_grid_sf = st_sf(area_hexagon_grid) %>% 
  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))
hexagon_grid_sf

hexagon_grid_sf$grid_id = lengths(st_intersects(hexagon_grid_sf, busstop))
hexagon_count = filter(hexagon_grid_sf, grid_id > 0)
```
## Step 3

Using `tmap`, the distribution of bus stops across Singapore can be visualised in the map below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
hexagon = tm_shape(hexagon_count)+
  tm_fill(
    col = "grid_id",
    palette = "Greens",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  )+
  tm_borders(col = "grey40", lwd = 0.7)
hexagon
```

:::

The geospatial distribution of bus stops in Singapore is extensive and dispersed throughout the region, with a notable concentration of stops with darker shades of red signifying higher concentrations. Outlying regions, along the coastal areas, show fewer bus stops as indicated by the presence of lighter-colored hexagons or even white spaces where no stops are present. This distribution pattern suggests a robust public transportation infrastructure in urban and densely populated areas, tapering off in less populated or industrial regions.

# 1.5 Explore data

`mapview` creates interactive visualisations of spatial data to examine and visually investigate both aspects of spatial data, the geometries and their attributes.

`plot()` takes parameters for specifying points in the diagram. At its simplest, it can plot two numbers against each other. With datasets, it can generate maps and plot the specified columns/attributes, with default up to nine plots or maximum all plots.

::: panel-tabset
## Bus Stop Distribution

The map below shows the overview of all bus stops in Singapore. Each dot represents a bus stop. 

```{r}
#| code-fold: true
#| code-summary: "Show the code"
mapview(busstop, cex = 3, alpha = 0.5, popup = NULL, col.regions = "darkseagreen")
```

## Bus Stop Density

High-density bus stop areas typically indicate regions with better **public transport accessibility**. This makes it easier for residents and visitors to move around without personal vehicles, which can reduce traffic congestion and the environmental impact of transportation. These regions may be **suburban town centres** with a higher concentration of services, amenities, and potentially population.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
highdensityhex <- hexagon_count[hexagon_count$grid_id > 8, ]


tmap_mode("view")

highdensity <- tm_basemap("OneMapSG.Grey") +
  tm_shape(highdensityhex) +
  tm_fill(
    col = "grid_id",
    palette = "Greens",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7) +
  tm_layout(
    title = "High-Density Bus Stops",
    title.size = 1
  ) +
  tm_shape(malls_sf) +
  tm_dots(size = 0.01, col = "cyan", title = "Malls") 

highdensity
```

The **top two** hexagons in dark green are further examined to understand these high density areas.

![](images/Screenshot%202023-12-01%20at%204.30.35%E2%80%AFPM.png){fig-align="left"}

![](images/Screenshot%202023-12-01%20at%204.30.06%E2%80%AFPM.png){fig-align="left"}

The hexagons are **dense residential areas**. It is observed that each hexagon have **no MRT stations** but usually a distance away where the bus network promotes a link to the MRT station and then to the city area. The hexagons also contain a **shopping mall** which promotes local economic activity and community interaction.

## Passenger Volume

To understand the passenger volume, we create a visual representation of the total number of trips made during different hours of the day, categorized by **weekdays** and **weekends/holidays**.

On weekdays, there is a prominent peak in trips during the morning hours (**6am to 9am**), followed by a decrease and then an increase during the evening hours (**5pm to 8pm**). This pattern is typical of commuter behavior, with high volumes of travel during morning and evening **peak hours** when people are generally traveling to and from work or school.

Weekends volume shows a different pattern, with the number of trips gradually increasing as the day progresses, peaking in the mid to late afternoon, and then tapering off. This suggests a **constant** travel throughout the day, which could be due to leisure activities, or social events during weekends or holidays.

Here we classify the peak hours by time intervals for four categories:
**Weekday morning peak**	6am to 9am
**Weekday afternoon peak**	5pm to 8pm
**Weekend/holiday morning peak**	11am to 2pm
**Weekend/holiday evening peak**	4pm to 7pm

```{r}
#| code-fold: true
#| code-summary: "Show the code"
time_interval <- function(day_type, time_per_hour) {
  if (day_type == "WEEKDAY") {
    if (time_per_hour >= 6 & time_per_hour <= 9) {
      "morning peak"
    } else if (time_per_hour >= 17 & time_per_hour <= 20) {
      "afternoon peak"
    } else {
      "non peak"
    }
  } else if (day_type == "WEEKENDS/HOLIDAY") {
    if (time_per_hour >= 11 & time_per_hour <= 14) {
      "morning peak"
    } else if (time_per_hour >= 16 & time_per_hour <= 19) {
      "evening peak"
    } else {
      "non peak"
    }
  } else {
    "non peak"
  }
}

odbus$TIME <- mapply(time_interval, odbus$DAY_TYPE, odbus$TIME_PER_HOUR)

head(odbus, n = 5)
```


```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$TIME_PER_HOUR <- factor(odbus$TIME_PER_HOUR)

total_trips <- odbus %>%
  group_by(DAY_TYPE, TIME_PER_HOUR) %>%
  summarise(Total_Trips = sum(TOTAL_TRIPS, na.rm = TRUE)) %>%
  ungroup()

max_trips <- max(total_trips$Total_Trips)

weekday_plot <- ggplot(data = filter(total_trips, DAY_TYPE == "WEEKDAY"), 
                       aes(x = TIME_PER_HOUR, y = Total_Trips, fill = as.factor(TIME_PER_HOUR))) +
  geom_bar(stat = "identity", width = 0.9) +
  labs(title = "Weekday Trips", x = "Hour of Day", y = "Total Trips") +
  theme_minimal() +
  ylim(0, max_trips) +
  scale_fill_viridis_d(option = "mako", guide = FALSE) + 
  theme(legend.position = "none",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))

weekend_plot <- ggplot(data = filter(total_trips, DAY_TYPE == "WEEKENDS/HOLIDAY"), 
                       aes(x = TIME_PER_HOUR, y = Total_Trips, fill = as.factor(TIME_PER_HOUR))) +
  geom_bar(stat = "identity", width = 0.9) +
  labs(title = "Weekend/Holiday Trips", x = "Hour of Day", y = "Total Trips") +
  theme_minimal() +
  ylim(0, max_trips) +
  scale_fill_viridis_d(option = "mako", guide = FALSE) +
  theme(legend.position = "none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))

grid.arrange(weekday_plot, weekend_plot, ncol = 2)
```
:::

# 1.6 Geovisualisation and Analysis

We will compute the passenger trips generated by origin

## Step 1 

`busstop` and `odbus` are joined by the bus stop codes to append geospatial objects the the passenger volume.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
passengertrips <- left_join(busstop, odbus, 
                            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
head(passengertrips, n=5)
```

## Step 2

Create two datasets `passengertrips_day` and `passengertrips_time`

::: panel-tabset

### Day
```{r}
#| code-fold: true
#| code-summary: "Show the code"
passengertrips_day <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY"], na.rm = TRUE),
    .groups = "drop"
  )
glimpse(passengertrips_day)
```
### Time
```{r}
#| code-fold: true
#| code-summary: "Show the code"
passengertrips_time <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKDAY_AFTERNOON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "afternoon peak"], na.rm = TRUE),
    WEEKDAY_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "evening peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    .groups = "drop"
  )

passengertrips_time <- passengertrips_time %>% 
  filter(!(WEEKDAY_MORNING_PEAK == 0 
           & WEEKDAY_AFTERNOON_PEAK == 0
           & WEEKDAY_NON_PEAK == 0
           & WEEKENDS_HOLIDAYS_MORNING_PEAK == 0
           & WEEKENDS_HOLIDAYS_EVENING_PEAK == 0
           & WEEKENDS_HOLIDAYS_NON_PEAK == 0))
glimpse(passengertrips_time)
```
:::

## Step 3

Ensure both datasets are in the same coordinate reference system (CRS).

::: panel-tabset
### Day

```{r}
st_crs(passengertrips_day)
```

### Time

```{r}
st_crs(passengertrips_time)
```

### Hexagon grid

```{r}
st_crs(hexagon_grid_sf)
```
:::

## Step 4: Perform a spatial join to match trips to hexagons

::: panel-tabset
### Day

```{r}
passengergrid_day <- st_join(hexagon_grid_sf, passengertrips_day, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_day <- passengergrid_day %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_day)
```

### Time

```{r}
passengergrid_time <- st_join(hexagon_grid_sf, passengertrips_time, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_time <- passengergrid_time %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_time)
```
:::

## Step 5: Split passengers trip into weekday and weekend

::: panel-tabset

### Day

```{r}
# Subset for Weekday
weekday_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekday_trips = sum(WEEKDAY_TRIPS, na.rm = TRUE),
  )

# Subset for Weekend
weekend_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekend_trips = sum(WEEKENDS_HOLIDAYS_TRIPS, na.rm = TRUE),
  )
```

### Time

```{r}
# First, ensure all necessary columns are present in the dataframe
passengergrid_clean <- passengergrid_time %>%
  mutate(
    WEEKDAY_MORNING_PEAK = ifelse(is.na(WEEKDAY_MORNING_PEAK), 0, WEEKDAY_MORNING_PEAK),
    WEEKDAY_AFTERNOON_PEAK = ifelse(is.na(WEEKDAY_AFTERNOON_PEAK), 0, WEEKDAY_AFTERNOON_PEAK),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_MORNING_PEAK), 0, WEEKENDS_HOLIDAYS_MORNING_PEAK),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_EVENING_PEAK), 0, WEEKENDS_HOLIDAYS_EVENING_PEAK)
  )

# Function to summarise and filter bus stops with no trips
summarise_and_filter <- function(data, column) {
  data %>%
    group_by(BUS_STOP_N) %>%
    summarise(Total_Trips = sum({{ column }}, na.rm = TRUE)) %>%
    filter(Total_Trips > 0) %>%
    ungroup()
}

# Create subsets using the function
weekday_morning_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKDAY_MORNING_PEAK)

weekday_afternoon_peak <- summarise_and_filter(passengergrid_clean, 
                                               WEEKDAY_AFTERNOON_PEAK)

weekend_morning_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKENDS_HOLIDAYS_MORNING_PEAK)

weekend_evening_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKENDS_HOLIDAYS_EVENING_PEAK)

# Check for any BUS_STOP_N that might still have issues
problematic_stops <- passengergrid_clean %>%
  filter(is.na(BUS_STOP_N)) %>%
  pull(BUS_STOP_N) %>%
  unique()

# If problematic_stops has any values, you may need to address these specifically,
# for example by removing them from passengergrid_clean before creating the subsets
if (length(problematic_stops) > 0) {
  passengergrid_clean <- passengergrid_clean %>%
    filter(!(BUS_STOP_N %in% problematic_stops))
}
```

## Step 6: Plot passenger trips traffic

::: panel-tabset
### Weekday Trips

```{r}
# Convert your data to an sf object if it's not one already
weekday_sf <- st_as_sf(weekday_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_sf$weekday_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_sf) +
  tm_polygons("weekday_trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

### Weekday Morning Peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_morning_peak_sf <- st_as_sf(weekday_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "weekday_morning_peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "weekday_morning_peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

### Weekday afternoon_peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_afternoon_peak_sf <- st_as_sf(weekday_afternoon_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_afternoon_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_afternoon_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Afternoon Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Afternoon Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

### Weekend Trips

```{r}
# Convert your data to an sf object if it's not one already
weekend_sf <- st_as_sf(weekend_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_sf$weekend_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_sf) +
  tm_polygons("weekend_trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

### Weekend morning peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_morning_peak_sf <- st_as_sf(weekend_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Morning Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Morning Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

### Weekend evening peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_evening_peak_sf <- st_as_sf(weekend_evening_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_evening_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_evening_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Evening Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Evening Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```
:::

# 1.6 Local Indicators of Spatial Association (LISA) Analysis

## 1.6.1 Compute LISA of the passengers trips generate by origin at hexagon level.

### Method 1: Computing Contiguity Spatial Weights

`poly2nb` defines the spatial relationship between different regions by computing contiguity weight matrices and build a neighbours list based on regions with contiguous boundaries.

::: panel-tabset
#### Day

```{r}
passengergrid_day_total <- passengergrid_day %>%
  mutate(TOTAL_TRIPS = WEEKDAY_TRIPS + WEEKENDS_HOLIDAYS_TRIPS)
```

```{r}
wm_q_day <- poly2nb(passengergrid_day_total, queen=TRUE)
summary(wm_q_day)
```

The output shown is a summary of a neighbors list object using Queen contiguity weight matrix. There are **5,029 regions** and approximately **42.69%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **21.47 neighboring regions**. For poorly connected regions, there are 7 regions without neighbors and 14 regions with 1 neighbour. There are 8 well-connected regions with 48 neighbours.

#### Time

```{r}
passengergrid_time_total <- passengergrid_time %>% 
  mutate(TOTAL_TRIPS = WEEKDAY_MORNING_PEAK + WEEKDAY_AFTERNOON_PEAK + WEEKDAY_NON_PEAK +
           WEEKENDS_HOLIDAYS_MORNING_PEAK + WEEKENDS_HOLIDAYS_EVENING_PEAK + WEEKENDS_HOLIDAYS_NON_PEAK)
```

```{r}
wm_q_time <- poly2nb(passengergrid_time_total, queen=TRUE)
summary(wm_q_time)
```

The output shown is a summary of a neighbors list object. There are **5,029 regions** and approximately **42.69%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **21.47 neighboring regions**. For poorly connected regions, there are 7 regions without neighbors and 14 regions with 1 neighbour. There are 8 well-connected regions with 48 neighbours.

```{r}
rswm_q_time <- nb2listw(wm_q_time, style="W", zero.policy = TRUE)
```

```{r}
fips_time <- order(passengergrid_time_total$BUS_STOP_N)
#localMI_time <- localmoran(passengergrid_time_total$TOTAL_TRIPS, rswm_q_time)
```
:::

### Method 2: Computing distance based neighbours

`passengergrid` is made up of polygons features, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids.

```{r}
longitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[1]])
latitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[2]])
```

```{r}
coords <- cbind(longitude, latitude)
head(coords)
```

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is **16228.8km**, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

```{r}
wm_d16229 <- dnearneigh(coords, 0, 16229, longlat = TRUE)
wm_d16229
```

```{r}
# Make a new list with only the first 5 elements
wm_d16229_subset <- wm_d16229[1:5]

# Now use str() on this subset
str(wm_d16229_subset)
```

```{r}
wm_d16229_lw <- nb2listw(wm_d16229, style = 'B')
summary(wm_d16229_lw)
```

Compute Gi statistics

```{r}
fips <- order(passengergrid_time_total$BUS_STOP_N)
gi.fixed <- localG(passengergrid_time_total$TOTAL_TRIPS, wm_d16229_lw)
```

```{r}
passengergrid_time_total.gi <- cbind(passengergrid_time_total, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

```{r}
#gi_total_trips <- qtm(passengergrid_time_total, "TOTAL_TRIPS")

Gimap_fixed <-tm_shape(passengergrid_time_total.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)
Gimap_fixed
#tmap_arrange(gi_total_trips, Gimap, asp=1, ncol=2)
```

Computing adaptive distance weight matrix

```{r}
knn <- knn2nb(knearneigh(coords, k=22))
knn
```

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

```{r}
fips_adaptive <- order(passengergrid_time_total$BUS_STOP_N)
gi.adaptive <- localG(passengergrid_time_total$TOTAL_TRIPS, knn_lw)
```

```{r}
passengergrid_time_total.gi <- cbind(passengergrid_time_total, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
Gimap_adaptive <-tm_shape(passengergrid_time_total.gi) +
  tm_fill(col = "gstat_adaptive", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi using adaptive weight matrix") +
  tm_borders(alpha = 0.5)
Gimap_adaptive
```

1.6.2 Display the LISA maps of the passengers trips generate by origin at hexagon level.

1.7 Emerging Hot Spot Analysis (EHSA)

1.7.1 Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values.

1.7.2 Prepared EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level.

weekday evening peak passenger trips by origin; hexagons dont not have shared boundary; isolated with no neighbours but a hotspot.
