---
title: "Dynamic Patterns of Public Transport Usage"
author: "Wan Kee"
date: "25 November 2023"
date modified: "25 November 2023"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# **A Geospatial Analysis of Bus Passenger Volume in Urban Environments**

# 1.1 Overview

In the intricate mosaic of urban transportation, bus stops serve as pivotal nodes that capture the pulse of city life through the ebb and flow of passenger trips. The study of passenger trip volume, particularly during peak hours, becomes essential for enhancing service efficiency, planning urban infrastructure, and improving the overall commuter experience.

This geospatial analysis is anchored in the bustling landscape of a metropolitan area, where data on bus stops, population distribution, urban development plans, and passenger volume intertwine to paint a comprehensive picture of transit dynamics.

This analysis aims to dissect the rhythms of urban mobility in Singapore through **geovisualization and emerging hot spot analysis (EHSA)** through spatio-temporal attributes.

# 1.2 Load packages

The analysis involves the following packages:

-   `sf` imports and handles geospatial data
-   `tidyverse` performs aspatial data import, wrangling and visualization
-   `dplyr` perform relational join
-   `spdep` compute spatial weights and spatially lagged variables
-   `spfep` compute spatial autocorrelation
-   `ggplot2`, `mapview` and `tmap` supports data visualisation

```{r}
pacman::p_load(sf, dplyr, ggplot2, knitr, mapview, spdep, sfdep, tmap, tidyverse)
```

# 1.3 Import data

We will be using the following **geospatial** (`busstop`, `subzone`) and **aspatial** (`odbus`, `malls`) datasets.

`st_geometry()` displays basic information of the feature class, such as type of geometry, the geographic extent of the features and the coordinate system of the data. `glimpse()` transposes the columns in a dataset and makes it possible to see the column name, data type and values within a data frame.

::: panel-tabset
## Bus Stop

`busstop` contains the detailed information for all bus stops currently serviced by buses, including bus stop code, road name, description, location coordinates. The output indicates that the geospatial objects are **point** features. There are **5161 features** and 3 fields. It is in **SVY21** projected coordinates system with **XY** dimension.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/BusStops))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop <- st_read(dsn = "data/BusStopLocation_Jul2023", layer = "BusStop") %>%
  st_transform(crs = 3414)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
st_geometry(busstop)
```

## Subzone

`mpsz` is the Master Plan 2019, a forward looking guiding plan for Singapore's development in the medium term over the next 10 to 15 years published in **2019**. Note this `mpsz` differs from that in previous chapter, [Data Wrangling](https://cosmic-kitten.netlify.app/hands_on_ex/hands_on_ex01/hands_on_ex01).

The output indicates that the geospatial objects are **multipolygon** features. There are **332 features** and 6 fields. It is in **WGS84** projected coordinates system with **XY** dimension.

Source: URA (Download [here](https://beta.data.gov.sg/collections/1749/view))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
mpsz = st_read(dsn="data/MPSZ-2019", layer="MPSZ-2019") %>% 
  st_transform(crs=3414)
```

## Passenger Volume

`odbus` contains the number of trips by weekdays and weekends from origin to destination bus stops. It reflects the passenger trip traffic and the most recent dataset from **October 2023** will be used. `odbus` is an aspatial data containing 5,694,297 records and 7 fields.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/PV/ODBus))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus = read_csv("data/origin_destination_bus_202310.csv")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)
glimpse(odbus)
```

The output indicates **5,694,297 records** and 7 fields. The bus stop codes are converted into factor for data handling.

## Population

`pop` contains Singapore residents grouped by planning area or subzone, age group, sex and floor area of residence. The data period is from **June 2011 onwards**. From June 2011 to 2019, the planning areas refer to areas demarcated in the Master Plan 2014, and from June 2020 onwards will be Master Plan 2019.

Source: Department of Statistics ([Link](https://www.singstat.gov.sg/-/media/files/find_data/population/statistical_tables/respopagesexfa2011to2020.ashx))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
pop <- read_csv("data/respopagesexfa2011to2020/respopagesexfa2011to2020.csv")
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
glimpse(pop)
```

The output indicates **738,492 records** and 7 fields to illustrate the population distribution by planning area (PA), subzone (SZ), age group (AG), residence floor area (FA), resident count (Pop).

## Passenger Volume

`odbus` contains the number of trips by weekdays and weekends from origin to destination bus stops. It reflects the passenger trip traffic for **October 2023**.

Source: LTA DataMall (Postman URL)

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus = read_csv("data/origin_destination_bus_202310.csv")
```

The output does not indicate any geospatial objects. There are 5,694,297 records and 7 fields.

## Malls

`malls` was a web scraper project conducted to scrape the list of shopping malls off a wikipedia site, and the the SVY21 coordinates from One Map API.

Source: Valary Lim ([GitHub](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/README.md))

```{r}
#| code-fold: true
#| code-summary: "Show the code"
malls <- read_csv("data/mall_coordinates_updated.csv")
```

`st_as_sf()` and `st_transforms()` uses the `longitude` and `latitude` to create spatial objects.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
malls_sf <- st_as_sf(malls,
                     coords = c("longitude","latitude"),
                     crs = 4326,
                     remove = F) %>% 
  st_transform(crs = 3414)
glimpse(malls_sf)
```
The output indicates that the geospatial objects are **point** features. There are **184 features** and 5 fields.

:::

# 1.4 Create Spatial Grids

**Spatial grids** are commonly used in spatial analysis to divide the study area into equal size, regular polygons that tessellate the area of interest. Square grid rarely reflect real world situations, whereas **hexagons** are compact and can overcome oddly-shaped geographical units.

`hexagon` is a hexagon layer of 250m where the distance is the perpendicular distance between the centre of the hexagon and its edges. It is a substitute for multipolygon in `mpsz` which is relatively coarse and irregular.

::: panel-tabset
## Step 1

First, we will create hexagonal grids using `st_make_grid()` to cover the geometry of `busstop`.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
area_hexagon_grid = st_make_grid(busstop, cellsize = 500, what = "polygons", square = FALSE)
area_hexagon_grid
```

The output indicates that the geospatial objects are **polygon** features. There are **5580 features** and 1 fields. It is in **SVY21** projected coordinates system with **XY** dimension, same as that in `busstop` dataset.

## Step 2

We also assign grid id to each hexagon using `length()` to calculate the length of the geometry and generate a sequence from 1 to the length of vectors in `area_hexagon_grid`.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
hexagon_grid_sf = st_sf(area_hexagon_grid) %>% 
  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))
hexagon_grid_sf
```

The output indicates that the geospatial objects retained **polygon** features and there are more than one polygon feature in a grid_id. The intersection of `busstop` and `hexagon_grid_sf` yields **1524 features** and 1 fields, indicating only 1524 out of 5580 features contains bus stops. It is in **SVY21** projected coordinates system with **XY** dimension.

## Step 3

The grids without any bus stops are removed to avoid errors in calculations.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
hexagon_grid_sf$grid_id = lengths(st_intersects(hexagon_grid_sf, busstop))
hexagon_count = filter(hexagon_grid_sf, grid_id > 0)
hexagon_count
```

## Step 4

Using `tmap`, the distribution of bus stops across Singapore can be visualised in the interactive map below.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
hexagon = tm_shape(hexagon_count)+
  tm_fill(
    col = "grid_id",
    palette = "Greens",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  )+
  tm_borders(col = "grey40", lwd = 0.7)
hexagon
```
:::

The geospatial distribution of bus stops in Singapore is extensive and dispersed throughout the region, with a notable concentration of stops with darker shades of red signifying higher concentrations. Outlying regions, along the coastal areas, show fewer bus stops as indicated by the presence of lighter-colored hexagons or even white spaces where no stops are present. This distribution pattern suggests a robust public transportation infrastructure in urban and densely populated areas, tapering off in less populated or industrial regions.

# 1.5 Explore data

`mapview` creates interactive visualisations of spatial data to examine and visually investigate both aspects of spatial data, the geometries and their attributes.

`plot()` takes parameters for specifying points in the diagram. At its simplest, it can plot two numbers against each other. With datasets, it can generate maps and plot the specified columns/attributes, with default up to nine plots or maximum all plots.

::: panel-tabset
## Distribution

The map below shows the location of each bus stop in Singapore.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
mapview(busstop, cex = 3, alpha = 0.5, popup = NULL, col.regions = "darkseagreen")
```

## High Density Areas

High-density bus stop areas typically indicate regions with better public transport accessibility. This makes it easier for residents and visitors to move around without personal vehicles, which can reduce traffic congestion and the environmental impact of transportation. These regions may be **suburban town centres** with a higher concentration of services, amenities, and potentially population.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
# Filter highdensityhex to include only the desired grid_id values
highdensityhex <- hexagon_count[hexagon_count$grid_id > 8, ]

# Set the tmap mode to interactive viewing
tmap_mode("view")

# Create the map
highdensity <- tm_basemap("OneMapSG.Grey") + # Use the same basemap as plot_wdm
  tm_shape(highdensityhex) +
  tm_fill(
    col = "grid_id",
    palette = "Greens",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  ) +
  tm_borders(col = "grey40", lwd = 0.7) +
  tm_layout(
    title = "High-Density Bus Stops",
    title.size = 1
  ) +
  tm_shape(malls_sf) +
  tm_dots(size = 0.01, col = "cyan", title = "Malls") 

# Print the map
highdensity
```

The top two hexagons are further examined to understand these high density areas.

![](images/Screenshot%202023-12-01%20at%204.30.35%E2%80%AFPM.png){fig-align="left"}

![](images/Screenshot%202023-12-01%20at%204.30.06%E2%80%AFPM.png){fig-align="left"}

The hexagons are residential areas a short distance from MRT stations to link these local centers to the city. Each hexagon also contains a shopping mall which promotes local economic activity and community interaction.

## Passenger Volume

```{r}
#| code-fold: true
#| code-summary: "Show the code"
# Summarize the total trips by day type
total_trips <- odbus %>%
  group_by(DAY_TYPE) %>%
  summarise(total = sum(TOTAL_TRIPS))

# Plot using ggplot2
ggplot(total_trips, aes(x = DAY_TYPE, y = total, fill = DAY_TYPE)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Total Trips by Day Type", x = "Day Type", y = "Total Trips")
```

## Subzone

```{r}
plot(mpsz["PLN_AREA_N"])
```
:::

# 1.6 Geovisualisation and Analysis

## 1.6.2 Compute the passenger trips generated by origin

### Step 1: Classify by time interval

```{r}
#| code-fold: true
#| code-summary: "Show the code"
# Function to assign peak and non-peak times
time_interval <- function(day_type, time_per_hour) {
  if (day_type == "WEEKDAY") {
    if (time_per_hour >= 6 & time_per_hour <= 9) {
      "morning peak"
    } else if (time_per_hour >= 17 & time_per_hour <= 20) {
      "afternoon peak"
    } else {
      "non peak"
    }
  } else if (day_type == "WEEKENDS/HOLIDAY") {
    if (time_per_hour >= 11 & time_per_hour <= 14) {
      "morning peak"
    } else if (time_per_hour >= 16 & time_per_hour <= 19) {
      "evening peak"
    } else {
      "non peak"
    }
  } else {
    "non peak"
  }
}

# Assuming 'odbus' is your data frame
odbus$TIME <- mapply(time_interval, odbus$DAY_TYPE, odbus$TIME_PER_HOUR)

# Checking the first few rows of the data frame to verify the new column
head(odbus)
```

### Step 2: Join datasets

```{r}
#| code-fold: true
#| code-summary: "Show the code"
passengertrips <- left_join(busstop, odbus, 
                            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
head(passengertrips, n=5)
```

::: panel-tabset
#### Day

```{r}
#| code-fold: true
#| code-summary: "Show the code"
passengertrips_day <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY"], na.rm = TRUE),
    .groups = "drop"
  )
```

#### Time

Determine peak or non peak

```{r}
passengertrips_time <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKDAY_AFTERNOON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "afternoon peak"], na.rm = TRUE),
    WEEKDAY_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "evening peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    .groups = "drop"
  )

passengertrips_time <- passengertrips_time %>% 
  filter(!(WEEKDAY_MORNING_PEAK == 0 
           & WEEKDAY_AFTERNOON_PEAK == 0
           & WEEKDAY_NON_PEAK == 0
           & WEEKENDS_HOLIDAYS_MORNING_PEAK == 0
           & WEEKENDS_HOLIDAYS_EVENING_PEAK == 0
           & WEEKENDS_HOLIDAYS_NON_PEAK == 0))
```
:::

### Step 3: Ensure both datasets are in the same coordinate reference system (CRS).

::: panel-tabset
#### Day

```{r}
st_crs(passengertrips_day)
```

#### Time

```{r}
st_crs(passengertrips_time)
```

#### Hexagon grid

```{r}
st_crs(hexagon_grid_sf)
```
:::

### Step 4: Perform a spatial join to match trips to hexagons

::: panel-tabset
#### Day

```{r}
passengergrid_day <- st_join(hexagon_grid_sf, passengertrips_day, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_day <- passengergrid_day %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_day)
```

#### Time

```{r}
passengergrid_time <- st_join(hexagon_grid_sf, passengertrips_time, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_time <- passengergrid_time %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_time)
```
:::

### Step 5: Split passengers trip into weekday and weekend

::: panel-tabset

#### Day

```{r}
# Subset for Weekday
weekday_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekday_trips = sum(WEEKDAY_TRIPS, na.rm = TRUE),
  )

# Subset for Weekend
weekend_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekend_trips = sum(WEEKENDS_HOLIDAYS_TRIPS, na.rm = TRUE),
  )
```

#### Time

```{r}
# First, ensure all necessary columns are present in the dataframe
passengergrid_clean <- passengergrid_time %>%
  mutate(
    WEEKDAY_MORNING_PEAK = ifelse(is.na(WEEKDAY_MORNING_PEAK), 0, WEEKDAY_MORNING_PEAK),
    WEEKDAY_AFTERNOON_PEAK = ifelse(is.na(WEEKDAY_AFTERNOON_PEAK), 0, WEEKDAY_AFTERNOON_PEAK),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_MORNING_PEAK), 0, WEEKENDS_HOLIDAYS_MORNING_PEAK),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_EVENING_PEAK), 0, WEEKENDS_HOLIDAYS_EVENING_PEAK)
  )

# Function to summarise and filter bus stops with no trips
summarise_and_filter <- function(data, column) {
  data %>%
    group_by(BUS_STOP_N) %>%
    summarise(Total_Trips = sum({{ column }}, na.rm = TRUE)) %>%
    filter(Total_Trips > 0) %>%
    ungroup()
}

# Create subsets using the function
weekday_morning_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKDAY_MORNING_PEAK)

weekday_afternoon_peak <- summarise_and_filter(passengergrid_clean, 
                                               WEEKDAY_AFTERNOON_PEAK)

weekend_morning_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKENDS_HOLIDAYS_MORNING_PEAK)

weekend_evening_peak <- summarise_and_filter(passengergrid_clean, 
                                             WEEKENDS_HOLIDAYS_EVENING_PEAK)

# Check for any BUS_STOP_N that might still have issues
problematic_stops <- passengergrid_clean %>%
  filter(is.na(BUS_STOP_N)) %>%
  pull(BUS_STOP_N) %>%
  unique()

# If problematic_stops has any values, you may need to address these specifically,
# for example by removing them from passengergrid_clean before creating the subsets
if (length(problematic_stops) > 0) {
  passengergrid_clean <- passengergrid_clean %>%
    filter(!(BUS_STOP_N %in% problematic_stops))
}
```

### Step 6: Plot passenger trips traffic

::: panel-tabset
#### Weekday Trips

```{r}
# Convert your data to an sf object if it's not one already
weekday_sf <- st_as_sf(weekday_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_sf$weekday_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_sf) +
  tm_polygons("weekday_trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekday Morning Peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_morning_peak_sf <- st_as_sf(weekday_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "weekday_morning_peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "weekday_morning_peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekday afternoon_peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_afternoon_peak_sf <- st_as_sf(weekday_afternoon_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_afternoon_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_afternoon_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Afternoon Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Afternoon Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekend Trips

```{r}
# Convert your data to an sf object if it's not one already
weekend_sf <- st_as_sf(weekend_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_sf$weekend_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_sf) +
  tm_polygons("weekend_trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekend morning peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_morning_peak_sf <- st_as_sf(weekend_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Morning Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Morning Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

#### Weekend evening peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_evening_peak_sf <- st_as_sf(weekend_evening_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_evening_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_evening_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Evening Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Evening Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```
:::

# 1.6 Local Indicators of Spatial Association (LISA) Analysis

## 1.6.1 Compute LISA of the passengers trips generate by origin at hexagon level.

### Method 1: Computing Contiguity Spatial Weights

`poly2nb` defines the spatial relationship between different regions by computing contiguity weight matrices and build a neighbours list based on regions with contiguous boundaries.

::: panel-tabset
#### Day

```{r}
passengergrid_day_total <- passengergrid_day %>%
  mutate(TOTAL_TRIPS = WEEKDAY_TRIPS + WEEKENDS_HOLIDAYS_TRIPS)
```

```{r}
wm_q_day <- poly2nb(passengergrid_day_total, queen=TRUE)
summary(wm_q_day)
```

The output shown is a summary of a neighbors list object using Queen contiguity weight matrix. There are **5,029 regions** and approximately **42.69%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **21.47 neighboring regions**. For poorly connected regions, there are 7 regions without neighbors and 14 regions with 1 neighbour. There are 8 well-connected regions with 48 neighbours.

#### Time

```{r}
passengergrid_time_total <- passengergrid_time %>% 
  mutate(TOTAL_TRIPS = WEEKDAY_MORNING_PEAK + WEEKDAY_AFTERNOON_PEAK + WEEKDAY_NON_PEAK +
           WEEKENDS_HOLIDAYS_MORNING_PEAK + WEEKENDS_HOLIDAYS_EVENING_PEAK + WEEKENDS_HOLIDAYS_NON_PEAK)
```

```{r}
wm_q_time <- poly2nb(passengergrid_time_total, queen=TRUE)
summary(wm_q_time)
```

The output shown is a summary of a neighbors list object. There are **5,029 regions** and approximately **42.69%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **21.47 neighboring regions**. For poorly connected regions, there are 7 regions without neighbors and 14 regions with 1 neighbour. There are 8 well-connected regions with 48 neighbours.

```{r}
rswm_q_time <- nb2listw(wm_q_time, style="W", zero.policy = TRUE)
```

```{r}
fips_time <- order(passengergrid_time_total$BUS_STOP_N)
#localMI_time <- localmoran(passengergrid_time_total$TOTAL_TRIPS, rswm_q_time)
```
:::

### Method 2: Computing distance based neighbours

`passengergrid` is made up of polygons features, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids.

```{r}
longitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[1]])
latitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[2]])
```

```{r}
coords <- cbind(longitude, latitude)
head(coords)
```

```{r}
k1 <- knn2nb(knearneigh(coords))
k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
summary(k1dists)
```

The summary report shows that the largest first nearest neighbour distance is **16228.8km**, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

```{r}
wm_d16229 <- dnearneigh(coords, 0, 16229, longlat = TRUE)
wm_d16229
```

```{r}
# Make a new list with only the first 5 elements
wm_d16229_subset <- wm_d16229[1:5]

# Now use str() on this subset
str(wm_d16229_subset)
```

```{r}
wm_d16229_lw <- nb2listw(wm_d16229, style = 'B')
summary(wm_d16229_lw)
```

Compute Gi statistics

```{r}
fips <- order(passengergrid_time_total$BUS_STOP_N)
gi.fixed <- localG(passengergrid_time_total$TOTAL_TRIPS, wm_d16229_lw)
```

```{r}
passengergrid_time_total.gi <- cbind(passengergrid_time_total, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```

```{r}
#gi_total_trips <- qtm(passengergrid_time_total, "TOTAL_TRIPS")

Gimap_fixed <-tm_shape(passengergrid_time_total.gi) +
  tm_fill(col = "gstat_fixed", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi") +
  tm_borders(alpha = 0.5)
Gimap_fixed
#tmap_arrange(gi_total_trips, Gimap, asp=1, ncol=2)
```

Computing adaptive distance weight matrix

```{r}
knn <- knn2nb(knearneigh(coords, k=22))
knn
```

```{r}
knn_lw <- nb2listw(knn, style = 'B')
summary(knn_lw)
```

```{r}
fips_adaptive <- order(passengergrid_time_total$BUS_STOP_N)
gi.adaptive <- localG(passengergrid_time_total$TOTAL_TRIPS, knn_lw)
```

```{r}
passengergrid_time_total.gi <- cbind(passengergrid_time_total, as.matrix(gi.adaptive)) %>%
  rename(gstat_adaptive = as.matrix.gi.adaptive.)
```

```{r}
Gimap_adaptive <-tm_shape(passengergrid_time_total.gi) +
  tm_fill(col = "gstat_adaptive", 
          style = "pretty",
          palette="-RdBu",
          title = "local Gi using adaptive weight matrix") +
  tm_borders(alpha = 0.5)
Gimap_adaptive
```

# 1.6.2 Display the LISA maps of the passengers trips generate by origin at hexagon level.

# 1.7 Emerging Hot Spot Analysis (EHSA)

# 1.7.1 Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values.

# 1.7.2 Prepared EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level.

# weekday evening peak passenger trips by origin; hexagons dont not have shared boundary; isolated with no neighbours but a hotspot.
