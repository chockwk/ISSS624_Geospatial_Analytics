---
title: "Dynamic Patterns of Public Transport Usage"
author: "Wan Kee"
date: "25 November 2023"
date modified: "25 November 2023"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: visual
---

# **A Geospatial Analysis of Bus Stop Passenger Volume in Urban Environments**

# 1.1 Overview

In the intricate mosaic of urban transportation, bus stops serve as pivotal nodes that capture the pulse of city life through the ebb and flow of passenger trips. The study of passenger trip generation, particularly during peak hours, becomes essential for enhancing service efficiency, planning urban infrastructure, and improving the overall commuter experience. This geospatial analysis is anchored in the bustling landscape of a metropolitan area, where data on bus stops, resident population distribution, urban development plans (master plan sub-zones), and passenger volume intertwine to paint a comprehensive picture of transit dynamics.

This analysis aims to dissect the rhythms of urban mobility with the following objectives:

1.  Geovisualization and Analysis

    -   Compute the passenger trips generated by origin at the hexagon level,

    -   Display the geographical distribution of the passenger trips by using appropriate geovisualisation methods,

    -   Describe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).

2.  Local Indicators of Spatial Association (LISA) Analysis

    -   Compute LISA of the passengers trips generate by origin at hexagon level. Display the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value \< 0.05) With reference to the analysis results, draw statistical conclusions (not more than 200 words per visual).

4.  Emerging Hot Spot Analysis(EHSA) With reference to the passenger trips by origin at the hexagon level for the four time intervals given above:

    -   Perform Mann-Kendall Test by using the spatio-temporal local Gi\* values,

    -   Prepared EHSA maps of the Gi\* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value \< 0.05). With reference to the EHSA maps and data visualisation prepared, describe the spatial patterns reveled. (not more than 250 words per cluster).

# 1.2 Load packages

`sf` `dplyr` `mapview` `tmap`

```{r}
pacman::p_load(knitr, mapview, spdep, tmap, tidyverse, sf)
```

# 1.3 Import data

::: panel-tabset
## Bus Stops

`busstops` contains the detailed information for all bus stops currently being serviced by buses, including bus stop code, road name, description, location coordinates. Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/BusStops))

```{r}
busstops <- st_read(dsn = "data/BusStopLocation_Jul2023", layer = "BusStop") %>%
  st_transform(crs = 3414)
```

The output indicates that the geospatial objects are **point** features. There are **5161 features** and 3 fields. It is in **SVY21** projected coordinates system with **XY** dimension.

## Population

Geospatial statistics are published by the Singapore Department of Statistics. They are available from the Population Trends, Census of Population and General Household Survey reports. Singapore Residents by Planning Area/Subzone, Age Group, Sex and Floor Area of Residence, June 2011 onwards

PA - Planning Area SZ - Subzone AG - Age Group Sex - Sex FA - Floor Area of Residence Pop - Resident Count Time - Time / Period

1)  For June 2011 to 2019, Planning Areas refer to areas demarcated in the Urban Redevelopment Authority's Master Plan 2014.
2)  For June 2020, Planning Areas refer to areas demarcated in the Urban Redevelopment Authority's Master Plan 2019.
3)  Data from 2003 onwards exclude residents who have been away from Singapore for a continuous period of 12 months or longer as at the reference period.
4)  The figures have been rounded to the nearest 10.
5)  The data may not add up due to rounding.

Source: Department of Statistics ([Link](https://www.singstat.gov.sg/-/media/files/find_data/population/statistical_tables/respopagesexfa2011to2020.ashx))

```{r}
popdata <- read_csv("data/respopagesexfa2011to2020/respopagesexfa2011to2020.csv")
```
## Passenger Volume
`odbus` contains the number of trips by weekdays and weekends from origin to destination bus stops. It indicates passenger volume for **October 2023**. Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/PV/ODBus))

```{r}
odbus = read_csv("data/origin_destination_bus_202310.csv")
```
The output does not indicate any geospatial objects. There are **5,694,297 records** and 7 fields.

## Subzone
Master Plan 2019 Subzone Boundary

The Master Plan is a forward looking guiding plan for Singapore's development in the medium term over the next 10 to 15 years published in **2019**. Note this `mpsz` differs from that in previous chapter, [Data Wrangling](https://cosmic-kitten.netlify.app/hands_on_ex/hands_on_ex01/hands_on_ex01).

`hexagon` is a hexagon layer of 250m (this distance is the perpendicular distance between the centre of the hexagon and its edges.) should be used to replace the relative coarse and irregular Master Plan 2019 Planning Sub-zone GIS data set of URA.

Source: URA (Download [here](https://beta.data.gov.sg/collections/1749/view))

```{r}
mpsz = st_read(dsn="data/MPSZ-2019", layer="MPSZ-2019") %>% 
  st_transform(crs=3414)
```
The output indicates that the geospatial objects are **multipolygon** features. There are **332 features** and 6 fields. It is in **WGS84** projected coordinates system with **XY** dimension.

```{r}
# Assuming mpsz is your sf object
#mpsz <- st_read(dsn="data/MP19_SUBZONE", layer="MP19_SUBZONE_NO_SEA")

# Ensure that 'geometry' is the active geometry column
#mpsz <- st_set_geometry(mpsz, "geometry")

# Check for invalid geometries and apply st_make_valid if needed
#mpsz$geometry_is_valid <- st_is_valid(mpsz$geometry)
#mpsz <- mpsz %>%
#  mutate(geometry = ifelse(!geometry_is_valid, st_make_valid(geometry), geometry))

# Now, remove the Z dimension explicitly if it exists
#mpsz <- st_zm(mpsz, drop = TRUE, what = "Z")

# View the data structure to confirm changes
#print(mpsz1)
```

::: {.callout-tip title="Warning"}
Warning: GDAL Message 1: Sub-geometry 0 has coordinate dimension 2, but container has 3
:::

The warning message indicate that a discrepancy in the dimensionality of the geometries in `mpsz` Shapefile. Some of the sub-geometries have 2D coordinates (X and Y), while the overall container expects 3D coordinates (X, Y, and Z). The `st_zm(what = "Z")` function drops the Z dimension from the geometries, which eliminate the warnings about coordinate dimensions. We are not performing 3D analysis, this approach should work fine for most applications.
:::

# 1.4 Create Spatial Grids

Spatial grids are commonly used in spatial analysis to divide the study area into equal size, regular polygons that tessellate the area of interest. On the selection of grid, regular geographic units, such as square grid or fishnets, rarely reflect real world situations. Hexagons are compact shape and can overcome oddly-shaped geographical units.

**Step 1: Create a hexgonal grid**

```{r}
# Create hexagonal grid (250m from center to edges)
area_hexagon_grid = st_make_grid(busstops, cellsize = 500, what = "polygons", square = FALSE)
area_hexagon_grid
```
**Step 2: Add Grid ID**

```{r}
hexagon_grid_sf = st_sf(area_hexagon_grid) %>% 
  mutate(grid_id = 1:length(lengths(area_hexagon_grid)))
hexagon_grid_sf
```
**Step 3: Count the number of bus stops in each grid and remove grids without any value.**
```{r}
hexagon_grid_sf$grid_id = lengths(st_intersects(hexagon_grid_sf, busstops))
hexagon_count = filter(hexagon_grid_sf, grid_id>0)
```

**Step 4: Set tmap to view mode for interactive plotting.**
```{r}
tmap_mode("view")
hexagon = tm_shape(hexagon_count)+
  tm_fill(
    col = "grid_id",
    palette = "Reds",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  )+
  tm_borders(col = "grey40", lwd = 0.7)
hexagon
```
# 1.5 Explore data
::: panel-tabset
## Bus Stops
```{r}
glimpse(busstops)
```
## Population
```{r}
glimpse(popdata)
```
## Passenger Volume
```{r}
glimpse(odbus)
```
## Subzone
```{r}
glimpse(mpsz)
```
:::

# 1.5 Plot data

::: panel-tabset
## Bus Stops
```{r}
location = mapview(busstops, cex = 3, alpha = 0.5, popup = NULL)
location
```

## Population
```{r}
popdata2020 <- popdata %>%
  filter(Time == 2020) %>%
  group_by(PA, SZ, AG) %>%
  summarise(`POP` = sum(`Pop`)) %>%
  ungroup() %>%
  pivot_wider(names_from=AG, values_from=POP) %>%
  mutate(YOUNG = rowSums(.[3:6]) + rowSums(.[12])) %>%
  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) + rowSums(.[13:15]))  %>%
  mutate(`AGED`=rowSums(.[16:21])) %>%
  mutate(`TOTAL`=rowSums(.[3:21])) %>%
  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %>%
  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)
```

## Passenger Volume

## Subzone
:::

# 1.6 Geovisualisation and Analysis

## 1.6.1 Compute the bus stop density 

```{r}
# Filter hexagons that contain more than 8 bus stops
hexagon_red = filter(hexagon_grid_sf, grid_id>8)

tmap_mode("view")
redhex = tm_shape(hexagon_red)+
  tm_fill(
    col = "grid_id",
    palette = "Reds",
    style = "cont",
    title = "Number of Bus Stops",
    id = "grid_id",
    showNA = FALSE,
    alpha = 0.6,
    popup.format = list(
      grid_id = list(format = "f", digits = 0)
    )
  )+
  tm_borders(col = "grey40", lwd = 0.7)
redhex
```

Sembawang MRT (9 bus stops)

![](images/Screenshot%202023-11-26%20at%206.01.46%E2%80%AFPM.png){fig-align="left" width="700"}

Pasir Ris (11 bus stops)

![](images/Screenshot%202023-11-27%20at%202.20.59%E2%80%AFAM.png){fig-align="left" width="700"}

## 1.6.2 Compute the passenger trips generated by origin

Step 1: 

Peak hour period	Bus tap on time
Weekday morning peak	6am to 9am
Weekday afternoon peak	5pm to 8pm
Weekend/holiday morning peak	11am to 2pm
Weekend/holiday evening peak	4pm to 7pm

```{r}
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)

# Function to assign peak and non-peak times
assign_time <- function(day_type, time_per_hour) {
  if (day_type == "WEEKDAY") {
    if (time_per_hour >= 6 & time_per_hour <= 9) {
      "morning peak"
    } else if (time_per_hour >= 17 & time_per_hour <= 20) {
      "afternoon peak"
    } else {
      "non peak"
    }
  } else if (day_type == "WEEKENDS/HOLIDAY") {
    if (time_per_hour >= 11 & time_per_hour <= 14) {
      "morning peak"
    } else if (time_per_hour >= 16 & time_per_hour <= 19) {
      "evening peak"
    } else {
      "non peak"
    }
  } else {
    "non peak"
  }
}

# Assuming 'odbus' is your data frame
odbus$TIME <- mapply(assign_time, odbus$DAY_TYPE, odbus$TIME_PER_HOUR)

# Checking the first few rows of the data frame to verify the new column
head(odbus)
```

Step 2: 
```{r}
passengertrips <- left_join(busstops, odbus, 
                            by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))
```

:::panel-tabset

# Day of Week

Determine weekday or weekend
```{r}
passengertrips_day <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_TRIPS = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY"], na.rm = TRUE),
    .groups = "drop"
  )
```

## Timing of Day

Determine peak or non peak
```{r}
passengertrips_time <- passengertrips %>%
  group_by(BUS_STOP_N, BUS_ROOF_N, LOC_DESC, YEAR_MONTH, geometry) %>%
  summarise(
    WEEKDAY_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKDAY_AFTERNOON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "afternoon peak"], na.rm = TRUE),
    WEEKDAY_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE == "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "morning peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "evening peak"], na.rm = TRUE),
    WEEKENDS_HOLIDAYS_NON_PEAK = sum(TOTAL_TRIPS[DAY_TYPE != "WEEKDAY" & TIME == "non peak"], na.rm = TRUE),
    .groups = "drop"
  )

passengertrips_time <- passengertrips_time %>% 
  filter(!(WEEKDAY_MORNING_PEAK == 0 
           & WEEKDAY_AFTERNOON_PEAK == 0
           & WEEKDAY_NON_PEAK == 0
           & WEEKENDS_HOLIDAYS_MORNING_PEAK == 0
           & WEEKENDS_HOLIDAYS_EVENING_PEAK == 0
           & WEEKENDS_HOLIDAYS_NON_PEAK == 0))
```
:::

Step 3: Ensure both datasets are in the same coordinate reference system (CRS).

::: panel-tabset

## Day of Week
```{r}
st_crs(passengertrips_day)
```

## Time of Week

```{r}
st_crs(passengertrips_time)
```

## Hexagon grid
```{r}
st_crs(hexagon_grid_sf)
```
:::

Step 4: Perform a spatial join to match trips to hexagons

::: panel-tabset
## Day of week
```{r}
passengergrid_day <- st_join(hexagon_grid_sf, passengertrips_day, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_day <- passengergrid_day %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_day)
```
## Time of Week

```{r}
passengergrid_time <- st_join(hexagon_grid_sf, passengertrips_time, join = st_intersects)
```

```{r}
# Remove rows with no trips (NA values)
passengergrid_time <- passengergrid_time %>% 
  filter(!is.na(BUS_STOP_N))
glimpse(passengergrid_time)
```
:::

Step 5: Split passengers trip into weekday and weekend

::: panel-tabset
## Day of Week
```{r}
# Subset for Weekday
weekday_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekday_trips = sum(WEEKDAY_TRIPS, na.rm = TRUE),
  )

# Subset for Weekend
weekend_trips <- passengergrid_day %>%
  group_by(BUS_STOP_N) %>%
  summarise(
    weekend_trips = sum(WEEKENDS_HOLIDAYS_TRIPS, na.rm = TRUE),
  )
```

## Time of Day



```{r}

# First, ensure all necessary columns are present in the dataframe
passengergrid_clean <- passengergrid_clean %>%
  mutate(
    WEEKDAY_MORNING_PEAK = ifelse(is.na(WEEKDAY_MORNING_PEAK), 0, WEEKDAY_MORNING_PEAK),
    WEEKDAY_AFTERNOON_PEAK = ifelse(is.na(WEEKDAY_AFTERNOON_PEAK), 0, WEEKDAY_AFTERNOON_PEAK),
    WEEKENDS_HOLIDAYS_MORNING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_MORNING_PEAK), 0, WEEKENDS_HOLIDAYS_MORNING_PEAK),
    WEEKENDS_HOLIDAYS_EVENING_PEAK = ifelse(is.na(WEEKENDS_HOLIDAYS_EVENING_PEAK), 0, WEEKENDS_HOLIDAYS_EVENING_PEAK)
  )

# Function to summarise and filter bus stops with no trips
summarise_and_filter <- function(data, column) {
  data %>%
    group_by(BUS_STOP_N) %>%
    summarise(Total_Trips = sum({{ column }}, na.rm = TRUE)) %>%
    filter(Total_Trips > 0) %>%
    ungroup()
}

# Create subsets using the function
weekday_morning_peak <- summarise_and_filter(passengergrid_clean, WEEKDAY_MORNING_PEAK)

weekday_afternoon_peak <- summarise_and_filter(passengergrid_clean, WEEKDAY_AFTERNOON_PEAK)

weekend_morning_peak <- summarise_and_filter(passengergrid_clean, WEEKENDS_HOLIDAYS_MORNING_PEAK)

weekend_evening_peak <- summarise_and_filter(passengergrid_clean, WEEKENDS_HOLIDAYS_EVENING_PEAK)

# Check for any BUS_STOP_N that might still have issues
problematic_stops <- passengergrid_clean %>%
  filter(is.na(BUS_STOP_N)) %>%
  pull(BUS_STOP_N) %>%
  unique()

# If problematic_stops has any values, you may need to address these specifically,
# for example by removing them from passengergrid_clean before creating the subsets
if (length(problematic_stops) > 0) {
  passengergrid_clean <- passengergrid_clean %>%
    filter(!(BUS_STOP_N %in% problematic_stops))
}

```

::: panel-tabset

## Weekday Trips

```{r}
# Convert your data to an sf object if it's not one already
weekday_sf <- st_as_sf(weekday_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_sf$weekday_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_sf) +
  tm_polygons("weekday_trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```
## Weekday Morning Peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_morning_peak_sf <- st_as_sf(weekday_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "weekday_morning_peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "weekday_morning_peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

## Weekday afternoon_peak

```{r}
# Convert your data to an sf object if it's not one already
weekday_afternoon_peak_sf <- st_as_sf(weekday_afternoon_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekday_afternoon_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekday_afternoon_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekday Afternoon Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Afternoon Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

## Weekend Trips
```{r}
# Convert your data to an sf object if it's not one already
weekend_sf <- st_as_sf(weekend_trips, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_sf$weekend_trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_sf) +
  tm_polygons("weekend_trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```

# Weekend morning peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_morning_peak_sf <- st_as_sf(weekend_morning_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_morning_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_morning_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Morning Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Morning Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```
## Weekend evening peaks

```{r}
# Convert your data to an sf object if it's not one already
weekend_evening_peak_sf <- st_as_sf(weekend_evening_peak, coords = c("longitude", "latitude"), crs = 4326) 

# Calculate breaks at intervals of 25,000
max_trips <- max(weekend_evening_peak_sf$Total_Trips, na.rm = TRUE)
breaks <- c(1, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

# Print the map
tmap_mode("view")
tm_shape(weekend_evening_peak_sf) +
  tm_polygons("Total_Trips", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks,
              title = "Weekend Evening Peak Trips") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Evening Peak Trips by Bus Stop", 
            main.title.position = "center", 
            frame = FALSE)
```
:::

# 1.6 Local Indicators of Spatial Association (LISA) Analysis

# 1.6.1 Compute LISA of the passengers trips generate by origin at hexagon level.

```{r}
# Remove rows with NA in BUS_STOP_N and calculate TOTAL_TRIPS
passengergrid_total <- passengergrid %>%
  mutate(TOTAL_TRIPS = WEEKDAY_TRIPS + WEEKENDS_HOLIDAYS_TRIPS)

```


```{r}
wm_q <- poly2nb(passengergrid_total, 
                queen=TRUE)
summary(wm_q)
```
```{r}
rswm_q <- nb2listw(wm_q, 
                   style="W")
rswm_q
```
```{r}

# Remove NA values from WEEKDAY_TRIPS
passengergrid_total <- passengergrid_total[!is.na(passengergrid_total$WEEKDAY_TRIPS),]

# Compute local Moran's I
#localIMI_weekday <- localmoran(passengergrid_total$WEEKDAY_TRIPS, rswm_q)

# View the results
#head(localIMI_weekday)

```


# 1.6.2 Display the LISA maps of the passengers trips generate by origin at hexagon level. 

# 1.7 Emerging Hot Spot Analysis (EHSA)

# 1.7.1 Perform Mann-Kendall Test by using the spatio-temporal local Gi* values.

# 1.7.2 Prepared EHSA maps of the Gi* values of the passenger trips by origin at the hexagon level. 

# weekday evening peak passenger trips by origin; hexagons dont not have shared boundary; isolated with no neighbours but a hotspot.
