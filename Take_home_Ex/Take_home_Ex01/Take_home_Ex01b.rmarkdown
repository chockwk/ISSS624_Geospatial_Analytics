---
title: "Dynamic Patterns of Public Transport Usage"
author: "Wan Kee"
date: "25 November 2023"
date modified: "3 December 2023"
format: html
execute: 
  echo: true
  eval: true
  warning: false
editor: source
---


# **A Geospatial Analysis of Passenger Volume in Urban Environments**

# 1. Overview

In the intricate mosaic of urban transportation, bus stops serve as pivotal nodes that capture the pulse of city life through the ebb and flow of passenger trips. The study of passenger trip volume, particularly during peak hours, becomes essential for enhancing service efficiency, planning urban infrastructure, and improving the overall commuter experience.

This geospatial analysis is anchored in the bustling landscape of a metropolitan area, where data on bus stops, population distribution, urban development plans, and passenger volume intertwine to paint a comprehensive picture of transit dynamics.

This analysis aims to dissect the rhythms of urban mobility in Singapore through **geovisualization** and **emerging hot spot analysis (EHSA)** through spatio-temporal attributes.

Geovisualization

1.  Compute the passenger trips generated by origin at a hexagon level of 250m for the following time intervals:

    a.  Weekday morning peak from 6am to 9am
    b.  Weekday evening peak from 5pm to 8pm
    c.  Weekend/holiday morning peak from 11am to 2pm
    d.  Weekend/holiday evening peak from 4pm to 7pm

2.  Display the geographical distribution of the passenger trips.

3.  Describe the spatial patterns revealed by the geovisualisation.

Emerging hot spot analysis (EHSA)

1.  Perform Mann-Kendall Test by using the spatio-temporal local G~i~\* values,

2.  Prepare EHSA maps of the G~i~\* values of the passenger trips by origin at the hexagon level and display the significant results (p-value \< 0.05).

3.  Describe the spatial patterns revealed in EHSA maps.

# 2. Load packages

The analysis involves the following packages:

-   `sf` imports and handles geospatial data
-   `DT` enables R data objects (matrices or data frames) to be displayed as tables on HTML pages.
-   `tidyverse` performs aspatial data import, wrangling and visualization
-   `spdep` compute spatial weights and spatially lagged variables
-   `spfep` compute spatial autocorrelation
-   `mapview` and `tmap` supports data visualisation


```{r}
pacman::p_load(sf, sp, DT, gridExtra, knitr, mapview, spdep, sfdep, tmap, tidyverse)
```


# 3. Import data

We will be using the following **geospatial** (`busstop`) and **aspatial** (`odbus`, `malls`) datasets.

`st_geometry()` displays basic information of the feature class, such as type of geometry, the geographic extent of the features and the coordinate system of the data. `glimpse()` transposes the columns in a dataset and makes it possible to see the column name, data type and values within a data frame.

::: panel-tabset
## Bus Stop

`busstop` is a **geospatial** dataset containing the detailed information for all bus stops currently serviced by buses, including bus stop code, road name, description, location coordinates.

The output indicates that the geospatial objects are **point** features. There are **5161 features** and 3 fields. It is in **SVY21** projected coordinates system with **XY** dimension.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/BusStops))


```{r}
busstop <- st_read(dsn = "data/BusStopLocation_Jul2023", layer = "BusStop") %>%
  st_transform(crs = 3414)
st_geometry(busstop)
```


## Passenger Volume

`odbus` is an **aspatial** dataset containing the number of trips by weekdays and weekends from origin to destination bus stops. It reflects the passenger trip traffic and the most recent dataset from **October 2023** will be used.

The output indicates **5,694,297 records** and 7 fields. The bus stop codes are converted into factor for data handling.

Source: LTA DataMall ([Postman URL](http://datamall2.mytransport.sg/ltaodataservice/PV/ODBus))


```{r}
odbus = read_csv("data/origin_destination_bus_202310.csv")
glimpse(odbus)
```


## Malls

`malls` is an aspatial transformed **spatial** dataset of shopping malls listed on a wikipedia site with SVY21 coordinates retrieved from One Map API. `st_as_sf()` and `st_transforms()` uses the `longitude` and `latitude` to create spatial objects.

The output indicates that the geospatial objects are **point** features. There are **184 features** and 5 fields.

Source: Valary Lim ([GitHub](https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper/blob/master/README.md))


```{r}
malls <- read_csv("data/mall_coordinates_updated.csv")
```

```{r}
malls_sf <- st_as_sf(malls,
                     coords = c("longitude","latitude"),
                     crs = 4326,
                     remove = F) %>% 
  st_transform(crs = 3414)
glimpse(malls_sf)
```

:::

# 4. Prepare data

:::panel-tabset

## Bus Stop: Remove duplicates

The output shows there are **32 duplicated rows** and these records will be removed using `distinct()` where only one records will be retained.

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop$BUS_STOP_N = as.factor(busstop$BUS_STOP_N)

duplicate <- busstop %>% 
  group_by(BUS_STOP_N) %>% 
  filter(n() > 1) %>% 
  arrange(BUS_STOP_N)

datatable(duplicate)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop <- busstop %>% 
  distinct(BUS_STOP_N,
           .keep_all = TRUE)
glimpse(busstop)
```

The output shows **5,145 records** remain after duplicated records are removed.

## Passenger Volume: Summarize trips


```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$ORIGIN_PT_CODE <- as.factor(odbus$ORIGIN_PT_CODE)
odbus$DESTINATION_PT_CODE <- as.factor(odbus$DESTINATION_PT_CODE)

odbus_trips <- odbus %>% 
  group_by(ORIGIN_PT_CODE, DAY_TYPE, TIME_PER_HOUR) %>% 
  summarise(TRIPS = sum(TOTAL_TRIPS))

head(odbus_trips, n=5)
```


## Passenger Volume: Imputation

Imputation for bus stops with no trips

`anti_join()` returns only rows from `busstop_list` that are not present in `odbus_trips` to identify all bus stops that do not have any trips recorded and impute 0.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
busstop_list = expand.grid(ORIGIN_PT_CODE = unique(busstop$BUS_STOP_N),
                           DAY_TYPE = c("WEEKDAY", "WEEKENDS/HOLIDAY"),
                           TIME_PER_HOUR = unique(odbus$TIME_PER_HOUR))

odbus_impute <- busstop_list %>%
  anti_join(odbus_trips, 
            by = c("ORIGIN_PT_CODE", "DAY_TYPE", "TIME_PER_HOUR")) %>%
  mutate(TRIPS = 0)
glimpse(odbus_impute)
```


Combine `busstop_list` and `odbus_impute` to create `odbus1` with all bus stops and trips.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus1 <- full_join(odbus_trips, odbus_impute)
glimpse(odbus1)
```


## Passenger Volume: Time Intervals

To understand the passenger volume, we create a visual representation of the total number of trips made during different hours of the day, categorized by **weekdays** and **weekends/holidays**. Note that weekdays accounts for five days, weekends accounts for 2 days and there is no public holiday in October 2023. Where the number of days differs in the day type, the passenger volume during weekdays is likely to see higher numbers.

Here we classify the peak hours by time intervals for four categories: - **Weekday morning peak** 6am to 9am - **Weekday afternoon peak** 5pm to 8pm - **Weekend/holiday morning peak** 11am to 2pm - **Weekend/holiday evening peak** 4pm to 7pm


```{r}
#| code-fold: true
#| code-summary: "Show the code"
TIME_INTERVAL <- function(DAY_TYPE, TIME_PER_HOUR) {
  if (DAY_TYPE == "WEEKDAY") {
    if (TIME_PER_HOUR >= 6 & TIME_PER_HOUR <= 9) {
      "WEEKDAY MORNING PEAK"
      } else if (TIME_PER_HOUR >= 17 & TIME_PER_HOUR <= 20) {
        "WEEKDAY AFTERNOON PEAK"
        } else {
          "WEEKDAY NON PEAK"
          }
    } else if (DAY_TYPE == "WEEKENDS/HOLIDAY") {
      if (TIME_PER_HOUR >= 11 & TIME_PER_HOUR <= 14) {
        "WEEKEND HOLIDAY MORNING PEAK"
        } else if (TIME_PER_HOUR >= 16 & TIME_PER_HOUR <= 19) {
          "WEEKEND HOLIDAY EVENING PEAK"
        } else {
          "WEEKEND HOLIDAY NON PEAK"
        }
      } else {
        "NON PEAK"
      }
  }

odbus1$TIME <- mapply(TIME_INTERVAL, odbus1$DAY_TYPE, odbus1$TIME_PER_HOUR)
head(odbus1, n=5)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus_pivot1 <- odbus1 %>% 
  group_by(ORIGIN_PT_CODE, TIME) %>% 
  summarise(TOTAL_TRIPS = sum(TRIPS), .groups = "drop") %>% 
  pivot_wider(names_from = TIME, values_from = TOTAL_TRIPS)

odbus_pivot2 <- odbus1 %>%
  filter(!(TIME == "WEEKDAY NON PEAK")) %>%
  filter(!(TIME == "WEEKEND HOLIDAY NON PEAK")) %>%
  group_by(ORIGIN_PT_CODE, DAY_TYPE, TIME_PER_HOUR) %>%
  summarise(TOTAL_TRIPS = sum(TRIPS), .groups = "drop") %>%
  mutate(Day_Time = paste(DAY_TYPE, TIME_PER_HOUR)) %>%
  ungroup %>%
  select(-c(DAY_TYPE, TIME_PER_HOUR)) %>%
  pivot_wider(names_from = Day_Time,
              values_from = TOTAL_TRIPS)

odbus2 <- right_join(odbus_pivot1, odbus_pivot2, by = join_by(ORIGIN_PT_CODE))
glimpse(odbus2)
```


## Merge Bus Stop and Passenger Volume


```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbusstop <- left_join(busstop, odbus2,
                       by = c("BUS_STOP_N"="ORIGIN_PT_CODE")
                       )
glimpse(odbusstop)
```

:::

# 5. Create Spatial Grids

**Spatial grids** are commonly used in spatial analysis to divide the study area into equal size, regular polygons that tessellate the area of interest. Square grid rarely reflect real world situations, whereas **hexagons** are compact and can overcome oddly-shaped geographical units.

`hexagon` is a hexagon layer of 250m where the distance is the perpendicular distance between the centre of the hexagon and its edges. It is a substitute for multipolygon in `mpsz` which is relatively coarse and irregular.

::: panel-tabset
## Step 1

First, we will create hexagonal grids using `st_make_grid()` to cover the geometry of `busstop`. The argument `cellsize` for hexagonal cells is numeric input of the distance between opposite edges where edge length is cellsize/sqrt(3) and the value of `500` creates a hexagon layer of 250m.
`what` can be polygons, corners, or centers.

The output indicates that the geospatial objects are **polygon** features. There are **5,580 features** and 1 fields. It is in **SVY21** projected coordinates system with **XY** dimension, same as that in `busstop` dataset.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
area_hexagon_grid <- st_make_grid(odbusstop, 
                                 cellsize = 500, 
                                 crs = 3414,
                                 what = "polygons",
                                 square = FALSE)
area_hexagon_grid
```


## Step 2

We also assign grid id to each hexagon using `row_number()` to generate a sequence from 1 to the length of vectors in `area_hexagon_grid`.

The output indicates that the geospatial objects retained **polygon** features and there are more than one polygon feature in a grid_id. The intersection of `busstop` and `hexagon_grid_sf` yields **1524 features** and 1 fields, indicating only 1524 out of 5580 features contains bus stops. It is in **SVY21** projected coordinates system with **XY** dimension.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
hexagon_grid_sf = st_sf(area_hexagon_grid) %>% 
  mutate(INDEX = row_number()) %>% 
  rename(geometry = area_hexagon_grid)
hexagon_grid_sf
```


## Step 3

`st_intersects()` combines `hexagon_grid_sf` and `busstop` and `filter()` removes empty grids.

Simple feature collection with 1524 features and 26 fields
Geometry type: POLYGON
Dimension:     XY
Bounding box:  xmin: 3720.122 ymin: 26193.43 xmax: 48720.12 ymax: 53184.55
Projected CRS: SVY21 / Singapore TM


```{r}
hexagon_count <- st_join(hexagon_grid_sf, odbusstop, 
                         join = st_intersects, 
                         left = TRUE) %>%
  filter(!(is.na(BUS_STOP_N))) %>%
  group_by(INDEX) %>%
  summarise(COUNT = n(),
            bus_stop_codes = paste(BUS_STOP_N, collapse = ", "),
            bus_stop_names = paste(LOC_DESC, collapse = ", "),
            across(starts_with("week"), sum)) %>%
  ungroup()

str(hexagon_count)
```

:::

Using `tmap`, the distribution of bus stops across Singapore can be visualised in the map below.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")

tm_shape(hexagon_count)+
  tm_fill(
    col = "COUNT",
    palette = "Greens",
    style = "cont",
    title = "Number of Bus Stops",
    alpha = 0.6)+
  tm_borders(col = "grey40", lwd = 0.7)
```

::: {.callout-note}
### Insight

The geospatial distribution of bus stops in Singapore is extensive and dispersed throughout the region, with a notable concentration of stops with darker shades of red signifying higher concentrations. Outlying regions, along the coastal areas, show fewer bus stops as indicated by the presence of lighter-colored hexagons or even white spaces where no stops are present. This distribution pattern suggests a robust public transportation infrastructure in urban and densely populated areas, tapering off in less populated or industrial regions.
:::


# 5. Explore data

`mapview` creates interactive visualisations of spatial data to examine and visually investigate both aspects of spatial data, the geometries and their attributes.

`plot()` takes parameters for specifying points in the diagram. At its simplest, it can plot two numbers against each other. With datasets, it can generate maps and plot the specified columns/attributes, with default up to nine plots or maximum all plots.

::: panel-tabset
## Bus Stop Distribution

The map below shows the overview of all bus stops in Singapore. Each dot represents a bus stop.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
mapview(odbusstop, cex = 3, alpha = 0.5, popup = NULL, col.regions = "darkseagreen")
```


## Bus Stop Density and Malls

High-density bus stop areas typically indicate regions with better **public transport accessibility**. This makes it easier for residents and visitors to move around without personal vehicles, which can reduce traffic congestion and the environmental impact of transportation. These regions may be **suburban town centres** with a higher concentration of services, amenities, and potentially population.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
highdensityhex <- hexagon_count[hexagon_count$COUNT > 8, ]

tmap_mode("view")

highdensity <- tm_basemap("OneMapSG.Grey") +
  tm_shape(highdensityhex) +
  tm_fill(col = "COUNT",
          palette = "Greens",
          title = "Number of Bus Stops",
          alpha = 0.6
          )+
  tm_borders(col = "grey40", lwd = 0.7) +
  tm_layout(
    title = "High-Density Bus Stops",
    title.size = 1
    ) +
  tm_shape(malls_sf) +
  tm_dots(size = 0.01, col = "cyan", title = "Malls")+
  tm_view(set.zoom.limits = c(11,13))

highdensity
```


The **top two** hexagons in dark green are further examined to understand these high density areas.

![](images/Screenshot%202023-12-01%20at%204.30.35%E2%80%AFPM.png){fig-align="left"}

![](images/Screenshot%202023-12-01%20at%204.30.06%E2%80%AFPM.png){fig-align="left"}
::: {.callout-note}
### Insight

The hexagons are **dense residential areas**. It is observed that each hexagon have **no MRT stations** but usually a distance away where the bus network promotes a link to the MRT station and then to the city area. The hexagons also contain a **shopping mall** which promotes local economic activity and community interaction.
:::

## Passenger Volume by Time Intervals


```{r}
#| code-fold: true
#| code-summary: "Show the code"
odbus$TIME_PER_HOUR <- factor(odbus$TIME_PER_HOUR)

total_trips <- odbus %>%
  group_by(DAY_TYPE, TIME_PER_HOUR) %>%
  summarise(Total_Trips = sum(TOTAL_TRIPS, na.rm = TRUE)) %>%
  ungroup()

max_trips <- max(total_trips$Total_Trips)

weekday_plot <- ggplot(data = filter(total_trips, DAY_TYPE == "WEEKDAY"), 
                       aes(x = TIME_PER_HOUR, y = Total_Trips, fill = as.factor(TIME_PER_HOUR))) +
  geom_bar(stat = "identity", width = 0.9) +
  labs(title = "Weekday Trips", x = "Hour of Day", y = "Total Trips") +
  theme_minimal() +
  ylim(0, max_trips) +
  scale_fill_viridis_d(option = "mako", guide = FALSE) + 
  theme(legend.position = "none",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))

weekend_plot <- ggplot(data = filter(total_trips, DAY_TYPE == "WEEKENDS/HOLIDAY"), 
                       aes(x = TIME_PER_HOUR, y = Total_Trips, fill = as.factor(TIME_PER_HOUR))) +
  geom_bar(stat = "identity", width = 0.9) +
  labs(title = "Weekend/Holiday Trips", x = "Hour of Day", y = "Total Trips") +
  theme_minimal() +
  ylim(0, max_trips) +
  scale_fill_viridis_d(option = "mako", guide = FALSE) +
  theme(legend.position = "none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))

grid.arrange(weekday_plot, weekend_plot, ncol = 2)
```

::: {.callout-note}
### Insight

On weekdays, there is a prominent peak in trips during the morning hours (**6am to 9am**), followed by a decrease and then an increase during the evening hours (**5pm to 8pm**). This pattern is typical of commuter behavior, with high volumes of travel during morning and evening **peak hours** when people are generally traveling to and from work or school.

Weekends volume shows a different pattern, with the number of trips gradually increasing as the day progresses, peaking in the mid to late afternoon, and then tapering off. This suggests a **constant** travel throughout the day, which could be due to leisure activities, or social events during weekends or holidays.

It is consistent with **bus operational hours** where no trips were made between 1am to 4am.
:::

:::

# 6. Geovisualisation and Analysis

We will compute the passenger trips using geospatial data from `busstop` and aspatial data from `odbus`.

::: Panel-tabset

## Passenger Volume by Intervals

Plot passenger trips traffic for each time interval using `tmap`.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
hexagon_count_tmap <- hexagon_count %>% 
  select(INDEX, COUNT, bus_stop_codes, 
         `WEEKDAY AFTERNOON PEAK`, `WEEKDAY MORNING PEAK`, `WEEKEND HOLIDAY EVENING PEAK`, `WEEKEND HOLIDAY MORNING PEAK`)

breaks <- c(0, 2500, 5000, 7500, 10000, 25000, 50000, Inf)

current_mode <- tmap_mode("plot")

# Weekday Morning Peak

weekday_morning_plot <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKDAY MORNING PEAK", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks) + 
  tm_scale_bar() +
  tm_layout(main.title = "Weekday Morning Peak", 
            main.title.position = "center",
            frame = FALSE,
            legend.show = FALSE)

# Weekday afternoon_peak

weekday_afternoon_plot <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKDAY AFTERNOON PEAK", 
              palette = "Blues", 
              border.col = "grey40",
              breaks = breaks) +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Afternoon Peak", 
            main.title.position = "center", 
            frame = FALSE,
            legend.outside = TRUE,
            legend.outside.position = "right",
            legend.text.size = 0.4)

# Weekend morning peaks

weekend_morning_plot <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKEND HOLIDAY MORNING PEAK", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks) +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Morning Peak", 
            main.title.position = "center", 
            frame = FALSE,
            legend.show = FALSE)

# Weekend evening peaks

weekend_evening_plot <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKEND HOLIDAY EVENING PEAK", 
              palette = "Purples", 
              border.col = "grey40",
              breaks = breaks) +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Evening Peak", 
            main.title.position = "center", 
            frame = FALSE,
            legend.outside = TRUE,
            legend.outside.position = "right",
            legend.text.size = 0.4)

tmap_arrange(weekday_morning_plot, weekday_afternoon_plot, weekend_morning_plot, weekend_evening_plot)
tmap_mode(current_mode)
```

::: {.callout-note}
### Insight

Binning by pre=determined **breaks** allows the comparison of passenger volume during peak hours on the **same scale**. Due to underlying difference in the number of days, weekdays are likely to see more passenger volume than weekends. Comparing the **weekday morning peak** and afternoon peak, there is more passenger volume observed in the **peripheral areas** where residents are commuting from residential areas (origin) to central areas (destinations). Whereas the **weekend** morning and evening peak has **constant** passenger volume originating from the same hexagons, indicating high activity levels in these popular areas.
:::

## Passenger Volume by Quantile


```{r}
#| code-fold: true
#| code-summary: "Show the code"
current_mode <- tmap_mode("plot")

# Weekday Morning Peak

weekday_morning_plot_q <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKDAY MORNING PEAK", 
              palette = "Blues", 
              border.col = "grey40",
              style = "quantile") + 
  tm_scale_bar() +
  tm_layout(main.title = "Weekday Morning Peak", 
            main.title.position = "center",
            frame = FALSE,
            legend.outside = TRUE,
            legend.outside.position = "right",
            legend.text.size = 0.4)

# Weekday afternoon_peak

weekday_afternoon_plot_q <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKDAY AFTERNOON PEAK", 
              palette = "Blues", 
              border.col = "grey40",
              style = "quantile") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekday Afternoon Peak", 
            main.title.position = "center", 
            frame = FALSE,
            legend.outside = TRUE,
            legend.outside.position = "right",
            legend.text.size = 0.4)

# Weekend morning peaks

weekend_morning_plot_q <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKEND HOLIDAY MORNING PEAK", 
              palette = "Purples", 
              border.col = "grey40",
              style = "quantile") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Morning Peak", 
            main.title.position = "center", 
            frame = FALSE,
            legend.outside = TRUE,
            legend.outside.position = "right",
            legend.text.size = 0.4)

# Weekend evening peaks

weekend_evening_plot_q <- tm_shape(hexagon_count_tmap) +
  tm_polygons("WEEKEND HOLIDAY EVENING PEAK", 
              palette = "Purples", 
              border.col = "grey40",
              style = "quantile") +
  tm_scale_bar()+
  tm_layout(main.title = "Weekend Evening Peak", 
            main.title.position = "center", 
            frame = FALSE,
            legend.outside = TRUE,
            legend.outside.position = "right",
            legend.text.size = 0.4)

tmap_arrange(weekday_morning_plot_q, weekday_afternoon_plot_q, weekend_morning_plot_q, weekend_evening_plot_q)
tmap_mode(current_mode)
```


::: {.callout-note}
### Insight

Binning by **quantiles** enables **relative comparison** of the passenger traffic between hexagons on the map.
:::

:::

# 7. Hot Spot and Cold Spot Area Analysis

## Space Time Cube

Spatio-temporal data often come in the form of single tables that can typically be categorized as **time-wide**, **space-wide**, or **long formats**. Space-wide data present each time period across each row and locational information in each column. Whereas a time-wide representation has location data down the rows and each time period is represented as a new column. In long formats, a row identifies a unique location and time observation represented by a column dedicated to time and another to locations. These flat formats are not linked to the geographies that they represent in any meaningful way. These flat files typically contain only an identifier of the location, but the spatial representation.

:::panel-tabset

### Weekday Morning


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_morning_hex <- hexagon_count %>%
  select(INDEX, COUNT, bus_stop_codes, geometry,
         `WEEKDAY 6`, `WEEKDAY 7`, `WEEKDAY 8`, `WEEKDAY 9`)
glimpse(weekday_morning_hex)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_morning_pivot <- st_join(hexagon_grid_sf, weekday_morning_hex, join = st_within)

weekday_morning_pivot <- weekday_morning_pivot %>%
  rename(INDEX = INDEX.x) %>% 
  rename_with(~gsub("WEEKDAY ", "", .), matches("^WEEKDAY \\d+$")) %>%
  pivot_longer(cols = c(`6`, `7`, `8`, `9`), 
               names_to = "TIME_PER_HOUR", values_to = "TRIPS",
               names_transform = as.integer, values_transform = as.integer) %>%
  mutate(across(where(is.integer), ~ifelse(is.na(.), 0, .))) %>%
  select(INDEX, TIME_PER_HOUR, TRIPS) %>%
  st_set_geometry(NULL)
```

```{r}
weekday_morning_cube <- spacetime(weekday_morning_pivot, hexagon_grid_sf,
                                  .loc_col = "INDEX", .time_col = "TIME_PER_HOUR")
glimpse(weekday_morning_cube)
```

```{r}
is_spacetime_cube(weekday_morning_cube)
```


### Weekday Afternoon


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_afternoon_hex <- hexagon_count %>%
  select(INDEX, COUNT, bus_stop_codes, geometry,
         `WEEKDAY 17`, `WEEKDAY 18`, `WEEKDAY 19`, `WEEKDAY 20`)
glimpse(weekday_afternoon_hex)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_afternoon_pivot <- st_join(hexagon_grid_sf, weekday_afternoon_hex, join = st_within)

weekday_afternoon_pivot <- weekday_afternoon_pivot %>%
  rename(INDEX = INDEX.x) %>% 
  rename_with(~gsub("WEEKDAY ", "", .), matches("^WEEKDAY \\d+$")) %>%
  pivot_longer(cols = c(`17`, `18`, `19`, `20`), 
               names_to = "TIME_PER_HOUR", values_to = "TRIPS",
               names_transform = as.integer, values_transform = as.integer) %>%
  mutate(across(where(is.integer), ~ifelse(is.na(.), 0, .))) %>%
  select(INDEX, TIME_PER_HOUR, TRIPS) %>%
  st_set_geometry(NULL)
```

```{r}
weekday_afternoon_cube <- spacetime(weekday_afternoon_pivot, hexagon_grid_sf,
                                  .loc_col = "INDEX", .time_col = "TIME_PER_HOUR")
glimpse(weekday_afternoon_cube)
```

```{r}
is_spacetime_cube(weekday_afternoon_cube)
```


### Weekend Holiday Morning


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_morning_hex <- hexagon_count %>%
  select(INDEX, COUNT, bus_stop_codes, geometry,
         `WEEKENDS/HOLIDAY 11`, `WEEKENDS/HOLIDAY 12`, `WEEKENDS/HOLIDAY 13`, `WEEKENDS/HOLIDAY 14`)
glimpse(weekend_morning_hex)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_morning_pivot <- st_join(hexagon_grid_sf, weekend_morning_hex, join = st_within)

weekend_morning_pivot <- weekend_morning_pivot %>%
  rename(INDEX = INDEX.x) %>% 
  rename_with(~gsub("WEEKENDS/HOLIDAY ", "", .), matches("^WEEKENDS/HOLIDAY \\d+$")) %>%
  pivot_longer(cols = c(`11`, `12`, `13`, `14`), 
               names_to = "TIME_PER_HOUR", values_to = "TRIPS",
               names_transform = as.integer, values_transform = as.integer) %>%
  mutate(across(where(is.integer), ~ifelse(is.na(.), 0, .))) %>%
  select(INDEX, TIME_PER_HOUR, TRIPS) %>%
  st_set_geometry(NULL)
```

```{r}
weekend_morning_cube <- spacetime(weekend_morning_pivot, hexagon_grid_sf,
                                  .loc_col = "INDEX", .time_col = "TIME_PER_HOUR")
glimpse(weekend_morning_cube)
```

```{r}
is_spacetime_cube(weekend_morning_cube)
```


### Weekend Holiday Evening


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_evening_hex <- hexagon_count %>%
  select(INDEX, COUNT, bus_stop_codes, geometry,
         `WEEKENDS/HOLIDAY 16`, `WEEKENDS/HOLIDAY 17`, `WEEKENDS/HOLIDAY 18`, `WEEKENDS/HOLIDAY 19`)
glimpse(weekend_morning_hex)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_evening_pivot <- st_join(hexagon_grid_sf, weekend_evening_hex, join = st_within)

weekend_evening_pivot <- weekend_evening_pivot %>%
  rename(INDEX = INDEX.x) %>% 
  rename_with(~gsub("WEEKENDS/HOLIDAY ", "", .), matches("^WEEKENDS/HOLIDAY \\d+$")) %>%
  pivot_longer(cols = c(`16`, `17`, `18`, `19`), 
               names_to = "TIME_PER_HOUR", values_to = "TRIPS",
               names_transform = as.integer, values_transform = as.integer) %>%
  mutate(across(where(is.integer), ~ifelse(is.na(.), 0, .))) %>%
  select(INDEX, TIME_PER_HOUR, TRIPS) %>%
  st_set_geometry(NULL)
```

```{r}
weekend_evening_cube <- spacetime(weekend_evening_pivot, hexagon_grid_sf,
                                  .loc_col = "INDEX", .time_col = "TIME_PER_HOUR")
glimpse(weekend_evening_cube)
```

```{r}
is_spacetime_cube(weekend_evening_cube)
```


:::

# 8. Local Gi* statistics

**Getis and Ord's G-statistics** looks at neighbours within a defined proximity to identify where either high or low values cluster spatially. Statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.

## Compute Contiguity Spatial Weights

`activate()` of dplyr activates the geometry context
`mutate()` of dplyr creates two new columns nb and wt
Then we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()
row order is very important so do not rearrange the observations after using set_nbs() or set_wts().
this dataset now has neighbors and weights for each time-slice.

We can use these new columns to manually calculate the local Gi* for each location. We can do this by grouping by Year and using local_gstar_perm() of sfdep package. After which, we use unnest() to unnest gi_star column of the newly created gi_starts data.frame.

:::panel-tabset

### Weekday Morning


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_morning_nb <- weekday_morning_cube %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")

head(weekday_morning_nb)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
gi_weekday_morning <- weekday_morning_nb %>%
  group_by(TIME_PER_HOUR) %>%
  mutate(gi_star = local_gstar_perm(TRIPS, nb, wt)) %>%
  tidyr::unnest(gi_star)

head(gi_weekday_morning, n=5)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggplot(data = gi_weekday_morning,
       aes(x = TIME_PER_HOUR, y = gi_star))+
  geom_line()+
  theme_light()+
  theme(legend.position = "none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))

```



### Weekday Afternoon


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_afternoon_nb <- weekday_afternoon_cube %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")

head(weekday_afternoon_nb)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
gi_weekday_afternoon <- weekday_afternoon_nb %>%
  group_by(TIME_PER_HOUR) %>%
  mutate(gi_star = local_gstar_perm(TRIPS, nb, wt)) %>%
  tidyr::unnest(gi_star)

head(gi_weekday_afternoon, n=5)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggplot(data = gi_weekday_afternoon,
       aes(x = TIME_PER_HOUR, y = gi_star))+
  geom_line()+
  theme_light()+
  theme(legend.position = "none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))
```


### Weekend Morning


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_morning_nb <- weekend_morning_cube %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")

head(weekend_morning_nb)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
gi_weekend_morning <- weekend_morning_nb %>%
  group_by(TIME_PER_HOUR) %>%
  mutate(gi_star = local_gstar_perm(TRIPS, nb, wt)) %>%
  tidyr::unnest(gi_star)

head(gi_weekend_morning, n=5)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggplot(data = gi_weekend_morning,
       aes(x = TIME_PER_HOUR, y = gi_star))+
  geom_line()+
  theme_light()+
  theme(legend.position = "none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))
```



### Weekend Evening


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_evening_nb <- weekend_evening_cube %>%
  activate("geometry") %>%
  mutate(nb = include_self(st_contiguity(geometry)),
         wt = st_inverse_distance(nb, geometry,
                                  scale = 1,
                                  alpha = 1),
         .before = 1) %>%
  set_nbs("nb") %>%
  set_wts("wt")

head(weekend_evening_nb)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
gi_weekend_evening <- weekend_evening_nb %>%
  group_by(TIME_PER_HOUR) %>%
  mutate(gi_star = local_gstar_perm(TRIPS, nb, wt)) %>%
  tidyr::unnest(gi_star)

head(gi_weekend_evening, n=5)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ggplot(data = gi_weekend_evening,
       aes(x = TIME_PER_HOUR, y = gi_star))+
  geom_line()+
  theme_light()+
  theme(legend.position = "none",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"))
```


# 9. Emerging Hot Spot Analysis (EHSA)

`emerging_hotspot_analysis()` identifies trends in spatial clustering over a period of time. It combines the **Getis-Ord Gi* statistic** with the **Mann-Kendall trend test** to determine if there is a temporal trend associated with local clustering of hot and cold spots. It works by first calculating the Gi* statistic for each location in each time period (time-slice). Next, for each location across all time-periods, the Mann-Kendall trend test is done to identify any temporal trend in Gi* values over all time periods. 


```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_morning_ehsa <- emerging_hotspot_analysis(
  x = weekday_morning_cube, 
  .var = "TRIPS", 
  k = 1, 
  nsim = 99
)
```

```{r}
glimpse(weekday_morning_ehsa)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekday_afternoon_ehsa <- emerging_hotspot_analysis(
  x = weekday_afternoon_cube, 
  .var = "TRIPS", 
  k = 1, 
  nsim = 99
)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_morning_ehsa <- emerging_hotspot_analysis(
  x = weekend_morning_cube, 
  .var = "TRIPS", 
  k = 1, 
  nsim = 99
)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
weekend_evening_ehsa <- emerging_hotspot_analysis(
  x = weekend_evening_cube, 
  .var = "TRIPS", 
  k = 1, 
  nsim = 99
)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
ehsa1 <- ggplot(data = weekday_morning_ehsa,
                aes(x = classification))+
  geom_bar()+
  labs(title = "Weekday Morning Peak")+
  theme_light()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"),
        axis.text = element_text(size = 6))

ehsa2 <- ggplot(data = weekday_afternoon_ehsa,
                aes(x = classification))+
  geom_bar()+
  labs(title = "Weekday Afternoon Peak")+
  theme_light()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"),
        axis.text = element_text(size = 6))

ehsa3 <- ggplot(data = weekend_morning_ehsa,
                aes(x = classification))+
  geom_bar()+
  labs(title = "Weekend Morning Peak")+
  theme_light()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"),
        axis.text = element_text(size = 6))

ehsa4 <- ggplot(data = weekend_evening_ehsa,
                aes(x = classification))+
  geom_bar()+
  labs(title = "Weekend Evening Peak")+
  theme_light()+
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "grey"),
        axis.text = element_text(size = 6))

grid.arrange(ehsa1, ehsa2, ehsa3, ehsa4, ncol = 1)
```


::: panel-tabset

## Weekday Morning

```{r}

classification_order <- c("no pattern detected", "new coldspot", "sporadic coldspot",
                          "new hotspot", "sporadic hotspot", "consecutive hotspot",
                          "persistent hotspot")

weekday_morning_ehsa$classification <- factor(weekday_morning_ehsa$classification, 
                                              levels = classification_order)

weekday_morning_ehsa_grid <- weekday_morning_hex %>%
  left_join(weekday_morning_ehsa,
            by = c("INDEX" = "location"))

weekday_morning_ehsa_signif <- weekday_morning_ehsa_grid  %>%
  filter(p_value < 0.1)

tmap_mode("view")

tm_shape(weekday_morning_ehsa_signif)+
  tm_fill("classification", palette = "Blues")+
  tm_borders(alpha = 0.4)+
  tm_view(set.zoom.limits = c(11,12))
```


## Weekday Afternoon


```{r}

weekday_afternoon_ehsa$classification <- factor(weekday_afternoon_ehsa$classification, 
                                              levels = classification_order)

weekday_afternoon_ehsa_grid <- weekday_afternoon_hex %>%
  left_join(weekday_afternoon_ehsa,
            by = c("INDEX" = "location"))

weekday_afternoon_ehsa_signif <- weekday_afternoon_ehsa_grid  %>%
  filter(p_value < 0.1)

tmap_mode("view")

tm_shape(weekday_afternoon_ehsa_signif)+
  tm_fill("classification", palette = "Blues")+
  tm_borders(alpha = 0.4)+
  tm_view(set.zoom.limits = c(11,12))
```


## Weekend Morning

```{r}
weekend_morning_ehsa$classification <- factor(weekend_morning_ehsa$classification, 
                                              levels = classification_order)

weekend_morning_ehsa_grid <- weekend_morning_hex %>%
  left_join(weekend_morning_ehsa,
            by = c("INDEX" = "location"))

weekend_morning_ehsa_signif <- weekend_morning_ehsa_grid  %>%
  filter(p_value < 0.1)

tmap_mode("view")

tm_shape(weekend_morning_ehsa_signif)+
  tm_fill("classification", palette = "Purples")+
  tm_borders(alpha = 0.4)+
  tm_view(set.zoom.limits = c(11,12))
```


## Weekend Evebing


```{r}

weekend_evening_ehsa$classification <- factor(weekend_evening_ehsa$classification, 
                                              levels = classification_order)

weekend_evening_ehsa_grid <- weekend_evening_hex %>%
  left_join(weekend_evening_ehsa,
            by = c("INDEX" = "location"))

weekend_evening_ehsa_signif <- weekend_evening_ehsa_grid  %>%
  filter(p_value < 0.1)

tmap_mode("view")

tm_shape(weekend_evening_ehsa_signif)+
  tm_fill("classification", palette = "Purples")+
  tm_borders(alpha = 0.4)+
  tm_view(set.zoom.limits = c(11,12))
```

:::


# 10. Conclusion

The geospatial analysis of transportation patterns in Singapore reveals **distinct hotspots of high commuter activity**, specifically in the areas of Boon Lay, Clementi, Woodlands, Ang Mo Kio, Bedok, and Tampines. These regions, characterized by their significant bus stop density and strategic importance in the **public transportation network**, serve as crucial nodes facilitating the mobility of a large number of commuters daily. The concentration of activity in these hotspots underscores their role as **essential transit hubs**, likely supported by a mix of residential, commercial, and industrial developments. The data suggests a high demand for public transportation services in these areas, which may be attributed to their development as **regional centers** and their connectivity to other parts of Singapore. As such, these hotspots could be focal points for future urban planning and transportation services enhancement to cater to the high volume of daily travelers efficiently.


# 11. Other workings:

`poly2nb` defines the spatial relationship between different regions by computing **contiguity weight matrices** and build a neighbours list based on regions with contiguous boundaries.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#wm_q <- poly2nb(hexagon_count, queen=TRUE)
#summary(wm_q)
```


The output shown is a summary of a neighbors list object. There are **1,524 regions** and approximately **29.62%** of all possible neighbor pairs are neighbors with nonzero links. Each region has an **average** of **4.51 neighboring regions**. For poorly connected regions, there are 10 regions without neighbors and 39 regions with 1 neighbour. There are 503 well-connected regions with 6 neighbours.

### Connectivity Graph

A **connectivity graph** takes a point and displays a line to each neighboring point.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#plot(passengergrid_time_total$area_hexagon_grid, border="grey")
#plot(wm_q_time, coords, pch = 19, cex = 0.1, add = TRUE, col= "darkseagreen")
```


## Method 2: Compute distance based neighbours

::: panel-tabset
### Step 1

Derive the centroid

`passengergrid` is made up of polygons features, so we will derive points to make our connectivity graphs. The most typically method is **polygon centroids**.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#longitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[1]])
#latitude <- map_dbl(passengergrid_time_total$area_hexagon_grid, ~st_centroid(.x)[[2]])
#coords <- cbind(longitude, latitude)
#head(coords)
```


### Step 2

Determine the cut-off distance

Determine the upper limit for distance band by using the steps below: 1. Return a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep. 2. Convert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb(). 3. Return the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise. 4. Remove the list structure of the returned object by using unlist().


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#k1 <- knn2nb(knearneigh(coords))
#k1dists <- unlist(nbdists(k1, coords, longlat = TRUE))
#summary(k1dists)
```


The summary report shows that the largest first nearest neighbour distance is **16228.8km**, so using this as the upper threshold gives certainty that all units will have at least one neighbour.

### Step 3a (fixed distance)

Compute fixed distance weight matrix using `dnearneigh()` where the lower distance bound is 0 and the upper distance bound is the largest neighbour distance. `longlat` is TRUE if point coordinates are geographical longitude-latitude decimal degrees, in which case distances are measured in kilometers.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#wm_d16229 <- dnearneigh(coords, 0, 16229, longlat = TRUE)
#wm_d16229
```


The output indicated there are 5,029 regions with an average of 4495 links.

`nb2listw()` converts the nb object into spatial weights object.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#wm_d16229_lw <- nb2listw(wm_d16229, style = 'B')
#summary(wm_d16229_lw)
```


The output indicated there is 1 least connected region with 4058 links and 4 most connected regions with 4818 links.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#plot(passengergrid_time_total$area_hexagon_grid, border="grey")
#plot(wm_d16229_lw, coords, pch = 19, cex = 0.1, add = TRUE, col= "darkseagreen")
```


### Step 3b (adaptive distance)

Computing adaptive distance weight matrix

`knearneigh()` obtains a matrix with the indices of points belonging to the set of the k nearest neighbours of each area. The number of neighbours can be imposed by `k` where the average number of neighbours is previously computed to be **21.47 neighboring regions**.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#knn <- knn2nb(knearneigh(coords, k=22))
#knn
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#knn_lw <- nb2listw(knn, style = 'B')
#summary(knn_lw)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
# plot(passengergrid_time_total$area_hexagon_grid, border="grey")
# plot(knn_lw, coords, pch = 19, cex = 0.1, add = TRUE, col= "darkseagreen")
```

:::

Gi statistics

The **local Getis-Ord statistic** is a ratio of the weighted average of the values in the neighboring locations to the sum of all values. It is called local g or local g\*, when not including the value at the location.

In local g/g\*, a value larger than the mean (or, a positive value for a standardized z-value) suggests a High-High cluster or hot spot, a value smaller than the mean (or, negative for a z-value) indicates a Low-Low cluster or cold spot.

::: panel-tabset
## Fixed Distance

Step 1: `localG()` calculate the local Geary statistic for a given variable and a neighbor list object `nb`.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#fips <- order(passengergrid_time_total$BUS_STOP_N)
#gi.fixed <- localG(passengergrid_time_total$TOTAL_TRIPS, wm_d16229_lw)
```


The output returns a dataframe with the following columns: gi: the observed statistic e_gi: the permutation sample mean var_gi: the permutation sample variance p_value: the p-value using sample mean and standard deviation p_folded_sim: p-value based on the implementation of Pysal which always assumes a two-sided test taking the minimum possible p-value

Step 2: `cbind()` joins the Gi values calculated from fixed distance weight matrix to their corresponding `passengergrid_time_total` sf data frame.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
passengergrid_time_total.gi <- cbind(passengergrid_time_total, as.matrix(gi.fixed)) %>%
  rename(gstat_fixed = as.matrix.gi.fixed.)
```


Step 3: Map the Gi values calculated from fixed distance weight matrix.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#gi_total_trips <- qtm(passengergrid_time_total, "TOTAL_TRIPS")
#Gimap_fixed <-tm_shape(passengergrid_time_total.gi) +
#  tm_fill(col = "gstat_fixed", 
#          style = "pretty",
#          palette="-RdBu",
#          title = "local Gi") +
#  tm_borders(alpha = 0.5)
#Gimap_fixed
#tmap_arrange(gi_total_trips, Gimap, asp=1, ncol=2)
```


The **Getis-Ord Gi\* statistic map** illustrates the **local spatial autocorrelation** of passenger volume during peak hours, indicating where high or low values cluster spatially. The colors indicate the z-scores from the Gi\* statistic. **Dark red** areas represent locations with **high z-scores**, indicating a cluster of **hot spots**. These are areas with a significantly higher passenger volume. **Dark blue** areas have **negative z-scores**, pointing to clusters of **cold spots**.

From the map, we can infer that there are distinct pockets where the passenger volume is significantly higher or lower than the average for the region. However, the distribution of hots spots and cold spots are dispersed and can be further improved by adaptive distance matrix.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#par(mfrow=c(1,2))
#plot(passengergrid_time_total$area_hexagon_grid, border="grey", main="1st nearest neighbours")
#plot(k1, coords, add=TRUE, col="lightblue", length=0.08)
#lot(passengergrid_time_total$area_hexagon_grid, border="grey", main="Distance link")
#plot(wm_d16229_lw, coords, add=TRUE, pch = 19, cex = 0.1)
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#gstar.fixed <- localG_perm(passengergrid_time_total$TOTAL_TRIPS, wm_d16229_lw, nsim = 499)
```


## Adaptive Distance

`localG()` compute the Gi values for `passengergrid_time_total` by using an adaptive distance weight matrix, `knb_lw`.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
#fips_adaptive <- order(passengergrid_time_total$BUS_STOP_N)
#gi.adaptive <- localG(passengergrid_time_total$TOTAL_TRIPS, knn_lw)

#passengergrid_time_total.gi <- cbind(passengergrid_time_total, as.matrix(gi.adaptive)) %>%
#  rename(gstat_adaptive = as.matrix.gi.adaptive.)

#Gimap_adaptive <-tm_shape(passengergrid_time_total.gi) +
#  tm_fill(col = "gstat_adaptive", 
#          style = "pretty",
#          palette="-RdBu",
#          title = "local Gi using adaptive weight matrix") +
#  tm_borders(alpha = 0.5)
#Gimap_adaptive
```

```{r}
#| code-fold: true
#| code-summary: "Show the code"
#tmap_mode("view")

#Gimap_adaptive_map <- tm_basemap("OneMapSG.Grey") +
#  tm_shape(passengergrid_time_total.gi) +
#  tm_fill(
#    col = "gstat_adaptive", 
#    palette="-RdBu",
#    style = "pretty",
#    id = "grid_id",
#    showNA = FALSE,
#    alpha = 0.3,
#    popup.format = list(
#      grid_id = list(format = "f", digits = 0)
#    )
#  ) +
#  tm_borders(col = "grey40", lwd = 0.7) +
#  tm_layout(
#   title = "local Gi using adaptive weight matrix",
#    title.size = 1
#  ) +
#  tm_shape(malls_sf) +
#  tm_dots(size = 0.01, col = "cyan", title = "Malls") 

#Gimap_adaptive_map
```


Compared to the previous map, which appears to use a fixed distance weight matrix, this map may show a different pattern of clustering due to the adaptive nature of the weight matrix. The hot spots and cold spots in the adaptive distance matrix map is **localized**, leading to a **finer resolution of clustering patterns** and can be particularly useful when the distribution of data points is uneven across the space.

**The hotspots are Boon Lay, Clementi, Woodlands, Ang Mo Kio, Bedok and Tampines.**
:::



